{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Trainer.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9IN3SD192go",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWEWOFA68xyU",
        "colab_type": "code",
        "outputId": "cd798407-f069-4c49-a396-949c9fd97cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"tf version {0} executing eagerly is {1}\".format(tf.__version__, tf.executing_eagerly()))\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "print(\"tfp version {0}\".format(tfp.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version 2.2.0-rc2 executing eagerly is True\n",
            "tfp version 0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P59ok20-3v4",
        "colab_type": "code",
        "outputId": "50f7c9ce-310e-4753-ee0c-04bb05bf8688",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = '/content/drive/My Drive/StoicNetData/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNWxIsIK9KvO",
        "colab_type": "code",
        "outputId": "785ff393-ef18-4103-fecb-8dcfd8243717",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "USE_GPU = True\n",
        "if USE_GPU:\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    print(\"Device name: \\\"{0}\\\"\".format(device_name))\n",
        "    if device_name != '/device:GPU:0':\n",
        "        \n",
        "        raise SystemError('GPU device not found')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            # Currently, memory growth needs to be the same across GPUs\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "        except RuntimeError as e:\n",
        "            # Memory growth must be set before GPUs have been initialized\n",
        "            print(e)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device name: \"/device:GPU:0\"\n",
            "Found GPU at: /device:GPU:0\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77kfnaVwt8Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import PIL\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('error', UserWarning)\n",
        "warnings.filterwarnings(\"error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFeV4R0mCQtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(98475651423)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts1EnJdX-V1f",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FbVWr08t8Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 112\n",
        "IMG_WIDTH = 112\n",
        "\n",
        "CK_keys_to_features = {\n",
        "    'image_neutral': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_expressive': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_other': tf.io.FixedLenFeature([], tf.string)\n",
        "}\n",
        "\n",
        "LFW_keys_to_features = {\n",
        "    'image': tf.io.FixedLenFeature([], tf.string)\n",
        "}\n",
        "\n",
        "def parserLFW(record):\n",
        "    parsed = tf.io.parse_single_example(record, LFW_keys_to_features)\n",
        "    \n",
        "    image = tf.io.decode_raw(parsed[\"image\"], tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.reshape(image, shape=[224,224,1])\n",
        "    image = tf.image.resize(image, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    image /= (255/2)\n",
        "    image -= 1\n",
        "    \n",
        "    return {\"image\":image}\n",
        "    \n",
        "def parserCK(record):\n",
        "    parsed = tf.io.parse_single_example(record, CK_keys_to_features)\n",
        "    \n",
        "    imageNeutral = tf.io.decode_raw(parsed[\"image_neutral\"], tf.uint8)\n",
        "    imageExpressive = tf.io.decode_raw(parsed[\"image_expressive\"], tf.uint8)\n",
        "    imageOther = tf.io.decode_raw(parsed[\"image_other\"], tf.uint8)\n",
        "    \n",
        "    imageNeutral = tf.cast(imageNeutral, tf.float32)\n",
        "    imageExpressive = tf.cast(imageExpressive, tf.float32)\n",
        "    imageOther = tf.cast(imageOther, tf.float32)\n",
        "    \n",
        "    imageNeutral = tf.reshape(imageNeutral, shape=[224,224,1])\n",
        "    imageExpressive = tf.reshape(imageExpressive, shape=[224,224,1])\n",
        "    imageOther = tf.reshape(imageOther, shape=[224,224,1])\n",
        "\n",
        "    imageNeutral = tf.image.resize(imageNeutral, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageExpressive = tf.image.resize(imageExpressive, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageOther = tf.image.resize(imageOther, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "\n",
        "    imageNeutral /= (255/2)\n",
        "    imageExpressive /= (255/2)\n",
        "    imageOther /= (255/2)\n",
        "    imageNeutral -= 1\n",
        "    imageExpressive -= 1\n",
        "    imageOther -= 1\n",
        "\n",
        "    #return {\"imageNeutral\":imageNeutral, \"imageExpressive\":imageExpressive, \"imageOther\":imageOther}\n",
        "    return {\"image\":imageExpressive}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtPS7faMt8V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 32\n",
        "latent_dim = 100\n",
        "\n",
        "DB_PATH = BASE_DIR\n",
        "\n",
        "\n",
        "raw_LFW_train = tf.data.TFRecordDataset(DB_PATH + \"trainLFW.tfrecords\")\n",
        "raw_LFW_test = tf.data.TFRecordDataset(DB_PATH + \"testLFW.tfrecords\")\n",
        "\n",
        "raw_CK_train = tf.data.TFRecordDataset(DB_PATH + \"train.tfrecords\")\n",
        "raw_CK_test = tf.data.TFRecordDataset(DB_PATH + \"test.tfrecords\")\n",
        "\n",
        "raw_novel = tf.data.TFRecordDataset(DB_PATH + \"novel.tfrecords\")\n",
        "\n",
        "\n",
        "parsed_LFW_train = raw_LFW_train.map(parserLFW)\n",
        "parsed_LFW_test = raw_LFW_test.map(parserLFW)\n",
        "\n",
        "#raw_CK_val = raw_test.shard(2,0)\n",
        "#raw_CK_test = raw_test.shard(2,1)\n",
        "parsed_CK_train = raw_CK_train.map(parserCK)\n",
        "#parsed_CK_val = raw_val.map(parserCK)\n",
        "parsed_CK_test = raw_CK_test.map(parserCK)\n",
        "\n",
        "parsed_train = parsed_LFW_train.concatenate(parsed_CK_train.shard(3,0)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "parsed_test  = parsed_LFW_test.concatenate(  parsed_CK_test.shard(3,0)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "parsed_novel = raw_novel.map(parserCK)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNgmQ6Wp-bA1",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8UhHQkBdxdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.random_normal_initializer(mean=0.0, stddev=0.02, seed=918273645)\n",
        "\n",
        "class Critic(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "        self.critique = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(512, kernel_initializer=init),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Dense(1, activation='linear', kernel_initializer=init),     # MAY WANT TO HAVE KEPT THIS AS LINEAR ACTIVATION\n",
        "        ], name=\"critique\")\n",
        "    \n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        return self.critique(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8plw2BSFYrQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encode = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2), use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2), use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim, kernel_initializer=init), # no activation...\n",
        "        ], name=\"encode\")\n",
        "    \n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        mean, logvar = tf.split(self.encode(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.decode = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim)),\n",
        "\n",
        "            tf.keras.layers.Dense(units=7*7*256),\n",
        "            tf.keras.layers.Reshape(target_shape=(7, 7, 256)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=128, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=64, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=32, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=16, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", use_bias=False, kernel_initializer=init,\n",
        "                activation=\"tanh\"),\n",
        "        ], name=\"decode\")\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, z):\n",
        "        return self.decode(z)\n",
        "\n",
        "\n",
        "class Enhancer(tf.keras.Model):\n",
        "    def __init__(self, num_filters):\n",
        "        super(Enhancer, self).__init__()\n",
        "        self.num_filters = num_filters\n",
        "        self.grow = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=num_filters, kernel_size=3, strides=(1, 1), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.PReLU(),\n",
        "        ], name=\"grow\")\n",
        "\n",
        "        self.enhance1 = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, num_filters)),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=num_filters, kernel_size=3, strides=(1,1), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.PReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=num_filters, kernel_size=3, strides=(1, 1), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "        ], name=\"enhance1\")\n",
        "            \n",
        "        self.add1 = tf.keras.layers.Add()\n",
        "\n",
        "        self.enhance2 = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, num_filters)),\n",
        "            tf.keras.layers.PReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=num_filters, kernel_size=3, strides=(1,1), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.PReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=num_filters, kernel_size=3, strides=(1, 1), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "        ], name=\"enhance2\")\n",
        "\n",
        "        self.add2 = tf.keras.layers.Add()\n",
        "\n",
        "        self.shrink = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, num_filters)),\n",
        "            tf.keras.layers.ReLU(),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", use_bias=False, kernel_initializer=init,\n",
        "                activation=\"tanh\"),\n",
        "        ], name=\"shrink\")\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        x = self.grow(x)\n",
        "        y = self.enhance1(x)\n",
        "        x = self.add1([x, y])\n",
        "        y = self.enhance2(x)\n",
        "        x = self.add2([x, y])\n",
        "        out = self.shrink(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def reparameterize(mean, logvar):\n",
        "    # Logvar used for numerical stability\n",
        "    epsilon = tf.random.normal(shape=mean.shape)\n",
        "    return epsilon * tf.exp(logvar * .5) + mean\n",
        "\n",
        "@tf.function\n",
        "def generateImg(enc, dec, x):\n",
        "    mean, logvar = enc(x)\n",
        "    return generateDist(dec, mean, logvar)\n",
        "\n",
        "@tf.function\n",
        "def generateDist(dec, mean, logvar):\n",
        "    z = reparameterize(mean, logvar)\n",
        "    return dec(z)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnpWNN29-gTk",
        "colab_type": "text"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_UU3x3Vt8V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prior = tfp.distributions.MultivariateNormalDiag(tf.zeros(latent_dim), tf.ones(latent_dim))\n",
        "dis_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "gen_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "@tf.function\n",
        "def add_noise(x):\n",
        "    noise_intensity = 1.0\n",
        "    noise = tf.multiply(noise_intensity, tf.random.normal(shape=x.shape, mean=0.0, stddev=0.3))\n",
        "    return tf.clip_by_value(tf.add(x, noise), -1.0, 1.0)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_apply_gradients_critic_only(enc, dec, enh, crt, x, crtOptimizer, Wkl, Wrl, Wgl):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        _, _, crtLoss = compute_loss(enc, dec, enh, crt, x, Wkl, Wrl, Wgl)\n",
        "\n",
        "    gradients_of_crt = tape.gradient(crtLoss, crt.trainable_variables)\n",
        "    crtOptimizer.apply_gradients(zip(gradients_of_crt, crt.trainable_variables))\n",
        "\n",
        "@tf.function\n",
        "def compute_apply_gradients(enc, dec, enh, crt, x, encOptimizer, decOptimizer, enhOptimizer, crtOptimizer, Wkl, Wrl, Wgl):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        encLoss, decLoss, enhLoss, crtLoss = compute_loss(enc, dec, enh, crt, x, Wkl, Wrl, Wgl)\n",
        "\n",
        "    gradients_of_enc = tape.gradient(encLoss, enc.trainable_variables)\n",
        "    gradients_of_dec = tape.gradient(decLoss, dec.trainable_variables)\n",
        "    gradients_of_enh = tape.gradient(enhLoss, enh.trainable_variables)\n",
        "    gradients_of_crt = tape.gradient(crtLoss, crt.trainable_variables)\n",
        "\n",
        "    encOptimizer.apply_gradients(zip(gradients_of_enc, enc.trainable_variables))\n",
        "    decOptimizer.apply_gradients(zip(gradients_of_dec, dec.trainable_variables))\n",
        "    enhOptimizer.apply_gradients(zip(gradients_of_enh, enh.trainable_variables))\n",
        "    crtOptimizer.apply_gradients(zip(gradients_of_crt, crt.trainable_variables))\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_loss(enc, dec, enh, crt, x, Wkl, Wrl, Wgl):\n",
        "    #Compute loss values\n",
        "    klLoss, recLoss1, recLoss2, genGanLoss, crtGanLoss = compute_ALL_loss(enc, dec, enh, crt, x)\n",
        "\n",
        "    klLoss     = tf.math.multiply(   Wkl, klLoss)\n",
        "    recLoss1   = tf.math.multiply(   Wrl, recLoss1)\n",
        "    recLoss2   = tf.math.multiply( 1-Wgl, recLoss2)\n",
        "    genGanLoss = tf.math.multiply(   Wgl, genGanLoss)\n",
        "\n",
        "    encLoss = tf.math.reduce_sum([\n",
        "        klLoss, recLoss1#, recLoss2\n",
        "    ])/2\n",
        "    decLoss = tf.math.reduce_sum([  \n",
        "                recLoss1#, recLoss2\n",
        "    ])\n",
        "    enhLoss = tf.math.reduce_sum([  \n",
        "                          recLoss2, genGanLoss\n",
        "    ])\n",
        "    crtLoss = crtGanLoss\n",
        "\n",
        "    return encLoss, decLoss, enhLoss, crtLoss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_ALL_loss(enc, dec, enh, crt, x):\n",
        "    mean, logvar = enc(x)\n",
        "\n",
        "    # KL Divergence Loss\n",
        "    posterior = tfp.distributions.MultivariateNormalDiag(mean, tf.exp(logvar * .5))\n",
        "    divergenceLoss = tf.reduce_mean(tfp.distributions.kl_divergence(posterior, prior))\n",
        "\n",
        "    # Reconstruction Loss for decoded image (MSE or RMSE)\n",
        "    generated_images = generateDist(dec, mean, logvar)\n",
        "    reconstructionLoss1 = reconstruction_loss(x, generated_images)\n",
        "\n",
        "    # Reconstruction Loss for enhanced image\n",
        "    enhanced_images = enh(generated_images)\n",
        "    reconstructionLoss2 = reconstruction_loss(x, enhanced_images)\n",
        "\n",
        "    # GAN Loss\n",
        "    real_scores = crt(x)    # May want to add noise?\n",
        "    dec_scores = crt(generated_images)\n",
        "    enh_scores = crt(enhanced_images)\n",
        "    genGanLoss, crtGanLoss = compute_lsgan_loss(real_scores, dec_scores, enh_scores)\n",
        "    \n",
        "    return divergenceLoss, reconstructionLoss1, reconstructionLoss2, genGanLoss, crtGanLoss\n",
        "\n",
        "@tf.function\n",
        "def compute_old_gan_loss(real_output, fake_output):\n",
        "    real_labels = tf.ones_like(real_output)\n",
        "    fake_labels = tf.zeros_like(fake_output)\n",
        "\n",
        "    dis_real_loss = dis_cross_entropy(real_labels, real_output) # Try not to be fooled\n",
        "    dis_fake_loss = dis_cross_entropy(fake_labels, fake_output) # Try not to be fooled\n",
        "    gen_fake_loss = gen_cross_entropy(real_labels, fake_output) # Try to fool\n",
        "\n",
        "    dis_gan_loss = tf.math.add(dis_real_loss, dis_fake_loss)\n",
        "    gen_gan_loss = gen_fake_loss\n",
        "    return gen_gan_loss, dis_gan_loss\n",
        "\n",
        "@tf.function\n",
        "def compute_lsgan_loss(real_output, dec_output, enh_output):\n",
        "    dis_gan_loss = 0.333 * tf.reduce_sum([\n",
        "        tf.reduce_mean((real_output - 1)**2),\n",
        "        tf.reduce_mean(dec_output**2),\n",
        "        tf.reduce_mean(enh_output**2)\n",
        "    ])\n",
        "    gen_gan_loss = tf.reduce_mean((enh_output - 1)**2)\n",
        "    return gen_gan_loss, dis_gan_loss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def reconstruction_loss(actual, generated):\n",
        "    return tf.reduce_mean(tf.math.square(tf.math.subtract(actual, generated)))\n",
        "\n",
        "@tf.function\n",
        "def cycle_loss(actual, generated):\n",
        "    return reconstruction_loss(encoder(actual), encoder(generated))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYqTTseY-ji2",
        "colab_type": "text"
      },
      "source": [
        "# I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag2zm_9h5w01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_StoicNet(prefix, full=False):\n",
        "    if prefix is None:\n",
        "        path_to_save = BASE_DIR + \"saved_model\"\n",
        "    else:\n",
        "        path_to_save = BASE_DIR + \"saved_model/{}\".format(prefix)\n",
        "    !mkdir -p \"{path_to_save}\"\n",
        "    print('Saving model at \"{}\"'.format(path_to_save))\n",
        "    if full:\n",
        "        encoder.save(path_to_save + \"/encoder.h5\")\n",
        "        decoder.save(path_to_save + \"/decoder.h5\")\n",
        "        enhancer.save(path_to_save + \"/enhancer.h5\")\n",
        "        critic.save(path_to_save + \"/critic.h5\")\n",
        "    else:\n",
        "        encoder.save_weights(path_to_save + \"/encoder.h5\")\n",
        "        decoder.save_weights(path_to_save + \"/decoder.h5\")\n",
        "        enhancer.save_weights(path_to_save + \"/enhancer.h5\")\n",
        "        critic.save_weights(path_to_save + \"/critic.h5\")\n",
        "\n",
        "\n",
        "def load_StoicNet(prefix):\n",
        "    if prefix is None:\n",
        "        path_to_save = BASE_DIR + \"saved_model\"\n",
        "    else:\n",
        "        path_to_save = BASE_DIR + \"saved_model/{}\".format(prefix)\n",
        "    \n",
        "    encoder.load_weights(path_to_save + \"/encoder.h5\")\n",
        "    decoder.load_weights(path_to_save + \"/decoder.h5\")\n",
        "    enhancer.load_weights(path_to_save + \"/enhancer.h5\")\n",
        "    critic.load_weights(path_to_save + \"/critic.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCD9--NTt8WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(epoch, test_input):\n",
        "    imgs = decoder(test_input)\n",
        "    assert not np.any(np.isnan(imgs))\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    for i in range(imgs.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    fig.tight_layout()\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def display_novel_images():\n",
        "    for image_features in parsed_novel:\n",
        "        first = image_features['imageNeutral']\n",
        "        second = image_features['imageExpressive']\n",
        "        third = image_features['imageOther']\n",
        "        test_input = np.array([first, second, third])\n",
        "\n",
        "        images = generateImg(encoder, decoder, test_input[0:3])\n",
        "        images_enhanced = enhancer(images)\n",
        "        ims = np.concatenate((test_input[0:3], images, images_enhanced), axis=0)\n",
        "        assert not np.any(np.isnan(ims))\n",
        "        fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(6,4))\n",
        "        for i in range(ims.shape[0]):\n",
        "            c = i % 3\n",
        "            r = i // 3\n",
        "            axes[r, c].imshow(ims[i, :, :, 0], cmap='gray')\n",
        "            axes[r, c].set_yticklabels([])\n",
        "            axes[r, c].xaxis.set_visible(False)\n",
        "        axes[0,0].set_ylabel(\"Inputs\", size='large')\n",
        "        axes[1,0].set_ylabel(\"Generated\", size='large')\n",
        "        axes[2,0].set_ylabel(\"Enhanced\", size='large')\n",
        "        fig.tight_layout()\n",
        "        #plt.savefig('novel_outputs.png')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def display_imgs_ratings(test_input, epoch=-1):\n",
        "    images = generateImg(encoder, decoder, test_input[0:8])\n",
        "    images_enhanced = enhancer(images)\n",
        "    ims = np.concatenate((test_input[0:8], images, images_enhanced), axis=0)\n",
        "    assert not np.any(np.isnan(ims))\n",
        "    fig, axes = plt.subplots(nrows=3, ncols=8, figsize=(11,4))\n",
        "    ratings = critic(ims)\n",
        "    for i in range(ims.shape[0]):\n",
        "        c = i % 8\n",
        "        r = i // 8\n",
        "        axes[r, c].set_title(\"{0:.6f}\".format(ratings[i,0]))\n",
        "        axes[r, c].imshow(ims[i, :, :, 0], cmap='gray')\n",
        "        axes[r, c].set_yticklabels([])\n",
        "        axes[r, c].xaxis.set_visible(False)\n",
        "    axes[0,0].set_ylabel(\"Inputs\", size='large')\n",
        "    axes[1,0].set_ylabel(\"Generated\", size='large')\n",
        "    axes[2,0].set_ylabel(\"Enhanced\", size='large')\n",
        "    fig.tight_layout()\n",
        "    if epoch >= 0:\n",
        "        plt.savefig('gens_at_epoch_{:04d}.png'.format(epoch))\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_ALL_loss(ls):\n",
        "    kl, rl1, rl2, gl, cl = zip(*ls)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.yaxis.tick_right()\n",
        "    plt.plot(kl, '-g', label='kL')\n",
        "    plt.plot(rl1, '-b', label='rL1')\n",
        "    plt.plot(rl2, '-c', label='rL2')\n",
        "    plt.plot(gl, '-y', label='gL')\n",
        "    plt.plot(cl, '-r', label='cL')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_feature_changes(epoch=None, base=None):\n",
        "    startTime = time.time()\n",
        "    print(\"Generating Feature Visualization\", end='')\n",
        "    steps = 15\n",
        "    magnitude = 3.0\n",
        "\n",
        "    # Build the feature vectors\n",
        "    if base is None:\n",
        "        independent_feature_vectors = np.zeros(shape=[steps*2+1, latent_dim, latent_dim])\n",
        "    else:\n",
        "        encoding = encoder(tf.expand_dims(base, 0))[0].numpy()\n",
        "        independent_feature_vectors = np.tile(np.repeat(encoding, latent_dim, axis=0), (steps*2+1, 1, 1))\n",
        "    for step in range(-1*steps, steps+1):\n",
        "        step_index = step + steps\n",
        "        mag = magnitude * (step/steps)\n",
        "        for feature_index in range(0, latent_dim):\n",
        "            independent_feature_vectors[step_index, feature_index, feature_index] = mag\n",
        "    print(\"!\", end='')\n",
        "\n",
        "    # Make the images\n",
        "    for step_index in range(0, steps*2+1):\n",
        "        print(\".\", end='')\n",
        "        encoding = independent_feature_vectors[step_index]\n",
        "        imgs = enhancer(decoder(encoding))\n",
        "        assert not np.any(np.isnan(imgs))\n",
        "        fig = plt.figure(figsize=(10,10))\n",
        "        for i in range(imgs.shape[0]):\n",
        "            plt.subplot(10, 10, i+1)\n",
        "            plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "            plt.axis('off')\n",
        "        fig.tight_layout()\n",
        "        plt.savefig('frame_{0:03}.png'.format(step_index))\n",
        "        plt.close(fig)\n",
        "\n",
        "    # Make the animation\n",
        "    if epoch is None:\n",
        "        anim_filename = BASE_DIR + 'TrainingGifs/features_' + time.strftime('%l:%M_%b_%d') + '.gif'\n",
        "    if type(epoch) is str:\n",
        "        anim_filename = BASE_DIR + 'TrainingGifs/features_{}_'.format(epoch) + time.strftime('%l:%M_%b_%d') + '.gif'\n",
        "    else:\n",
        "        anim_filename = BASE_DIR + 'TrainingGifs/features_epoch_{}_'.format(epoch) + time.strftime('%l:%M_%b_%d') + '.gif'\n",
        "    print(\"\\nSaving gif at: \" + anim_filename)\n",
        "    with imageio.get_writer(anim_filename, mode='I') as writer:\n",
        "        filenames = glob.glob('frame_*.png')\n",
        "        filenames = sorted(filenames)\n",
        "        filenames = filenames + filenames[::-1] # Go full circle\n",
        "        for i,filename in enumerate(filenames):\n",
        "            image = imageio.imread(filename)\n",
        "            writer.append_data(image)\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    print(\"Done in {} seconds\".format(time.time()-startTime))\n",
        "\n",
        "\n",
        "def display_image_features(image, name=None):\n",
        "    if name is None:\n",
        "        filename = BASE_DIR + 'TrainingGifs/image_features'\n",
        "        print(\"Generating Image Feature Visualization\", end='')\n",
        "    else:\n",
        "        filename = BASE_DIR + 'TrainingGifs/image_features_{}'.format(epoch)\n",
        "        print(\"Generating Image Feature Visualization for {}\".format(name), end='')\n",
        "    \n",
        "    fig = plt.figure()\n",
        "    plt.imshow(image[:,:,0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(filename + \"FULL\")\n",
        "    #plt.close(fig)\n",
        "    \n",
        "    # Build the feature vectors\n",
        "    encoding = encoder(tf.expand_dims(image, 0))[0]\n",
        "\n",
        "    independent_encodings = np.zeros(shape=[latent_dim, latent_dim])\n",
        "    for feature_index in range(0, latent_dim):\n",
        "        feature_value = encoding[0][feature_index]\n",
        "        independent_encodings[feature_index, feature_index] = feature_value\n",
        "\n",
        "    # Make the images\n",
        "    imgs = enhancer(decoder(independent_encodings))\n",
        "    assert not np.any(np.isnan(imgs))\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    for i in range(imgs.shape[0]):\n",
        "        plt.subplot(10, 10, i+1)\n",
        "        plt.imshow(imgs[i,:,:,0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(filename + \"BREAKDOWN\")\n",
        "    #plt.close(fig)\n",
        "    print(\"\\t\\tDone!\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8-Siz9x6MpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#display_image_features(random_images_for_generation[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXYOThHMQdx6",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgD6yo2vn-Zl",
        "colab_type": "code",
        "outputId": "8d84c84b-4980-4a69-ec16-2d311e9f274b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_examples_to_generate = 16\n",
        "\n",
        "random_vector_for_generation = tf.random.normal(shape=[num_examples_to_generate, latent_dim])\n",
        "#random_images_for_generation = [image_features['imageExpressive'] for image_features in parsed_CK_test.take(1)][0][0:num_examples_to_generate]\n",
        "random_images_for_generation = [image_features['image'] for image_features in parsed_test.take(1)][0][0:num_examples_to_generate]\n",
        "print(\"random inputs generated\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random inputs generated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QH0nPiz0yVO",
        "colab_type": "code",
        "outputId": "b4f5074b-075f-435d-eb22-3decf96cc214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "epochs = 150\n",
        "extra_critic_training_rounds = 0\n",
        "\n",
        "encOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5)\n",
        "decOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5)\n",
        "enhOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5)\n",
        "crtOptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n",
        "print(\"optimizers created\")\n",
        "\n",
        "encoder = Encoder(latent_dim); print(\"encoder built\")\n",
        "decoder = Decoder(latent_dim); print(\"decoder built\")\n",
        "enhancer = Enhancer(num_filters=32); print(\"enhancer built\")\n",
        "critic = Critic(); print(\"critic built\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "optimizers created\n",
            "encoder built\n",
            "decoder built\n",
            "enhancer built\n",
            "critic built\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVDQ_wJVdezn",
        "colab_type": "code",
        "outputId": "ec897511-4c87-4ed8-f87b-0698fc5f7eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "FRESH = False\n",
        "if not FRESH:\n",
        "    load_StoicNet(\"TEMP_SAVE_100\")\n",
        "    startEpoch = 51  #technically 100, but whatever\n",
        "    print(\"Training loaded model from epoch {}\".format(startEpoch))\n",
        "else:\n",
        "    print(\"Training a fresh model\")\n",
        "    startEpoch = 0"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loaded model from epoch 51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "jqNw-Wqht8WG",
        "colab_type": "code",
        "outputId": "cf0f20fc-0ddd-49a0-988d-7c47e42df6e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Wkl (aka beta) weighs KL Divergence loss, limiting encoding capacity \n",
        "Wkl = tf.convert_to_tensor(0.003, dtype=tf.float32)\n",
        "max_Wkl = 0.003\n",
        "Wkl_ramp_start = -1   # Ramps up\n",
        "Wkl_ramp_end = 10\n",
        "# Tried:\n",
        "# 0.001 (too low     with Wrl=5, Wgl=1)\n",
        "# 0.01  (better      with Wrl=5, Wgl=0.5)\n",
        "# 0.05  (too high    with Wrl=5, Wgl=0.25)\n",
        "# 0.03  (too high    with Wrl=5, Wgl=0.25)\n",
        "# 0.02  (too high    with Wrl=5, Wgl=0 -> .75)(enhancing)\n",
        "# 0.005 (little high with Wrl=5, Wgl=0 -> .75)(enhancing)\n",
        "# 0.003 (not too shabby with ' ,   '         )(enhancing)\n",
        "\n",
        "\n",
        "# Wrl weighs reconstruction loss 1\n",
        "Wrl = tf.convert_to_tensor(5.0, dtype=tf.float32)\n",
        "max_Wrl = 5.0\n",
        "Wrl_ramp_start = 1   # Ramps up\n",
        "Wrl_ramp_end = 15\n",
        "\n",
        "# Wgl weighs gan loss vs reconstruction loss 2 for generator\n",
        "Wgl = tf.convert_to_tensor(0.015, dtype=tf.float32)\n",
        "max_Wgl = 0.015\n",
        "Wgl_ramp_start = 50   # Ramps up\n",
        "Wgl_ramp_end = 60\n",
        "\n",
        "ls = []\n",
        "bestLoss = 999999.9\n",
        "start_time = time.time()\n",
        "for epoch in range(startEpoch, epochs):\n",
        "    # Train\n",
        "    Wkl = min(max_Wkl, max_Wkl * (max(0, (epoch - Wkl_ramp_start)) / (Wkl_ramp_end - Wkl_ramp_start)))\n",
        "    Wkl = tf.convert_to_tensor(Wkl, dtype=tf.float32)\n",
        "\n",
        "    #Wgl = min(max_Wgl, max_Wgl * (max(0, (epoch - Wgl_ramp_start)) / (Wgl_ramp_end - Wgl_ramp_start)))\n",
        "    #Wgl = tf.convert_to_tensor(Wgl, dtype=tf.float32)\n",
        "\n",
        "    for training_round in range(0, extra_critic_training_rounds):\n",
        "        print(\"\\nTraining Critic Round {}\".format(training_round), end=\"\")\n",
        "        batchCounter = 0\n",
        "        for image_features in parsed_train:\n",
        "            image_raw = image_features['image']\n",
        "\n",
        "            compute_apply_gradients_critic_only(\n",
        "                encoder, decoder, enhancer, critic,\n",
        "                image_raw, crtOptimizer,\n",
        "                Wkl, Wrl, Wgl)\n",
        "\n",
        "            batchCounter += 1\n",
        "            if batchCounter % 10 == 0:\n",
        "                print(\".\", end=\"\")\n",
        "    \n",
        "    print(\"\\nTraining All\", end=\"\")\n",
        "    batchCounter = 0\n",
        "    for image_features in parsed_train:\n",
        "        image_raw = image_features['image']\n",
        "\n",
        "        compute_apply_gradients(\n",
        "            encoder, decoder, enhancer, critic,\n",
        "            image_raw,\n",
        "            encOptimizer, decOptimizer, enhOptimizer, crtOptimizer,\n",
        "            Wkl, Wrl, Wgl)\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "    \n",
        "    # Test\n",
        "    print(\"\\nTesting All\", end=\"\")\n",
        "    batchCounter = 0\n",
        "    kloss = tf.keras.metrics.Mean()\n",
        "    rloss1 = tf.keras.metrics.Mean()\n",
        "    rloss2 = tf.keras.metrics.Mean()\n",
        "    gloss = tf.keras.metrics.Mean()\n",
        "    closs = tf.keras.metrics.Mean()\n",
        "    for image_features in parsed_test:\n",
        "        image_raw = image_features['image']\n",
        "\n",
        "        kl, rl1, rl2, gl, cl = compute_ALL_loss(\n",
        "            encoder, decoder, enhancer, critic,\n",
        "            image_raw)\n",
        "        \n",
        "        kloss(kl)\n",
        "        rloss1(rl1)\n",
        "        rloss2(rl2)\n",
        "        gloss(gl)\n",
        "        closs(cl)\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "\n",
        "    kl_base = kloss.result().numpy()\n",
        "    kl = tf.math.multiply(kloss.result(), Wkl).numpy()\n",
        "    rl1 = tf.math.multiply(rloss1.result(), Wrl).numpy()\n",
        "    rl2 = tf.math.multiply(rloss2.result(), 1-Wgl).numpy()\n",
        "    gl = tf.math.multiply(gloss.result(), Wgl).numpy()\n",
        "    cl = closs.result().numpy()\n",
        "    ls = ls + [(kl, rl1, rl2, gl, cl)]\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    # Output\n",
        "    display.clear_output(wait=False)\n",
        "    print('Epoch {0}, Total epoch time {1:.1f}'.format(epoch, end_time-start_time))\n",
        "    print('Losses: k {0:.5f}({1:.5f}x{2:.5f})  r1 {3:.5f}  (r2 {4:.5f} g {5:.6f})({6:.5f})  c {7:.5f}'.format(\n",
        "            kl, Wkl, kl_base, rl1, rl2, gl, Wgl, cl))\n",
        "    plot_ALL_loss(ls)\n",
        "    display_imgs_ratings(random_images_for_generation)\n",
        "    #save_images(epoch, random_vector_for_generation)\n",
        "    #display_novel_images()\n",
        "\n",
        "    # Save the model from time to time or if you get a new record (after sufficient training)\n",
        "    if epoch > 20 and kl + rl2 + gl < bestLoss:\n",
        "        bestLoss = kl + rl2 + gl\n",
        "        save_StoicNet(\"TEMP_BEST_MODEL\")\n",
        "        print(\"*Saved new best*\")\n",
        "    if (epoch + 1) % 25 == 0:\n",
        "        display_feature_changes(epoch+1)\n",
        "        save_StoicNet(\"TEMP_SAVE\")\n",
        "    elif (epoch + 1) % 5 == 0:\n",
        "        save_StoicNet(\"TEMP_SAVE\")\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training All........................................................................"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhpVx7DzQYuB",
        "colab_type": "text"
      },
      "source": [
        "# Save & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MyW7bvwStaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveName = \"FINAL_SAVE_\"+time.strftime('%l_%M_%b%d')\n",
        "save_StoicNet(saveName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxmHNJVTk1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_feature_changes(epoch=\"FINAL\")\n",
        "display_feature_changes(epoch=\"good guy test\", base=random_images_for_generation[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1l2PxZpcsQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# anim_filename = BASE_DIR + 'TrainingGifs/vaegan' + time.strftime('%l:%M %b %d') + '.gif'\n",
        "# print(anim_filename)\n",
        "# with imageio.get_writer(anim_filename, mode='I') as writer:\n",
        "#     filenames = glob.glob('image_at_epoch_*.png')\n",
        "#     filenames = sorted(filenames)\n",
        "#     last = -1\n",
        "#     for i,filename in enumerate(filenames):\n",
        "#         frame = 2*(i**0.5)\n",
        "#         if round(frame) > round(last):\n",
        "#             last = frame\n",
        "#         else:\n",
        "#             continue\n",
        "#         image = imageio.imread(filename)\n",
        "#         writer.append_data(image)\n",
        "#     image = imageio.imread(filename)\n",
        "#     writer.append_data(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4i_YSqdQYQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(latent_dim)\n",
        "decoder = Decoder(latent_dim)\n",
        "load_StoicNet(saveName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb_MvTfbRpW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_imgs_ratings(random_images_for_generation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irwxzovcnYum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_novel_images()\n",
        "print(encoder(test_input))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}