{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Trainer.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWEWOFA68xyU",
        "colab_type": "code",
        "outputId": "21b3ba93-1763-467e-987f-faf5249de8ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"tf version {0} executing eagerly is {1}\".format(tf.__version__, tf.executing_eagerly()))\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "print(\"tfp version {0}\".format(tfp.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version 2.2.0-rc2 executing eagerly is True\n",
            "tfp version 0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P59ok20-3v4",
        "colab_type": "code",
        "outputId": "9994d545-8f59-443d-d649-6d90a1625c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = '/content/drive/My Drive/StoicNetData/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNWxIsIK9KvO",
        "colab_type": "code",
        "outputId": "59160c67-a263-4642-e749-c016378c1a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "print(\"Device name: \\\"{0}\\\"\".format(device_name))\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device name: \"\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-97da25b4d38f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Device name: \\\"{0}\\\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77kfnaVwt8Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import PIL\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('error', UserWarning)\n",
        "warnings.filterwarnings(\"error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFeV4R0mCQtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(98475651423)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FbVWr08t8Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 112\n",
        "IMG_WIDTH = 112\n",
        "\n",
        "CK_keys_to_features = {\n",
        "    'image_neutral': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_expressive': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_other': tf.io.FixedLenFeature([], tf.string)\n",
        "}\n",
        "\n",
        "LFW_keys_to_features = {\n",
        "    'image': tf.io.FixedLenFeature([], tf.string)\n",
        "}\n",
        "\n",
        "def parserLFW(record):\n",
        "    parsed = tf.io.parse_single_example(record, LFW_keys_to_features)\n",
        "    \n",
        "    image = tf.io.decode_raw(parsed[\"image\"], tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.reshape(image, shape=[224,224,1])\n",
        "    image = tf.image.resize(image, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    image /= (255/2)\n",
        "    image -= 1\n",
        "    \n",
        "    return {\"image\":image}\n",
        "    \n",
        "def parserCK(record):\n",
        "    parsed = tf.io.parse_single_example(record, CK_keys_to_features)\n",
        "    \n",
        "    imageNeutral = tf.io.decode_raw(parsed[\"image_neutral\"], tf.uint8)\n",
        "    imageExpressive = tf.io.decode_raw(parsed[\"image_expressive\"], tf.uint8)\n",
        "    imageOther = tf.io.decode_raw(parsed[\"image_other\"], tf.uint8)\n",
        "    \n",
        "    imageNeutral = tf.cast(imageNeutral, tf.float32)\n",
        "    imageExpressive = tf.cast(imageExpressive, tf.float32)\n",
        "    imageOther = tf.cast(imageOther, tf.float32)\n",
        "    \n",
        "    imageNeutral = tf.reshape(imageNeutral, shape=[224,224,1])\n",
        "    imageExpressive = tf.reshape(imageExpressive, shape=[224,224,1])\n",
        "    imageOther = tf.reshape(imageOther, shape=[224,224,1])\n",
        "\n",
        "    imageNeutral = tf.image.resize(imageNeutral, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageExpressive = tf.image.resize(imageExpressive, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageOther = tf.image.resize(imageOther, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "\n",
        "    imageNeutral /= (255/2)\n",
        "    imageExpressive /= (255/2)\n",
        "    imageOther /= (255/2)\n",
        "    imageNeutral -= 1\n",
        "    imageExpressive -= 1\n",
        "    imageOther -= 1\n",
        "\n",
        "    return {\"imageNeutral\":imageNeutral, \"imageExpressive\":imageExpressive, \"imageOther\":imageOther}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtPS7faMt8V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 32\n",
        "latent_dim = 100\n",
        "\n",
        "DB_PATH = BASE_DIR\n",
        "\n",
        "\n",
        "raw_LFW_train = tf.data.TFRecordDataset(DB_PATH + \"trainLFW.tfrecords\")\n",
        "raw_LFW_test = tf.data.TFRecordDataset(DB_PATH + \"testLFW.tfrecords\")\n",
        "parsed_LFW_train = raw_LFW_train.map(parserLFW).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "parsed_LFW_test = raw_LFW_test.map(parserLFW).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "raw_CK_train = tf.data.TFRecordDataset(DB_PATH + \"train.tfrecords\")\n",
        "raw_CK_test = tf.data.TFRecordDataset(DB_PATH + \"test.tfrecords\")\n",
        "\n",
        "#raw_CK_val = raw_test.shard(2,0)\n",
        "#raw_CK_test = raw_test.shard(2,1)\n",
        "\n",
        "parsed_CK_train = raw_CK_train.map(parserCK).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "#parsed_CK_val = raw_val.map(parserCK).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "parsed_CK_test = raw_CK_test.map(parserCK).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "raw_novel = tf.data.TFRecordDataset(DB_PATH + \"novel.tfrecords\")\n",
        "parsed_novel = raw_novel.map(parserCK)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8UhHQkBdxdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.random_normal_initializer(mean=0.0, stddev=0.02, seed=918273645)\n",
        "\n",
        "class Critic(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "        self.critique = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(512, kernel_initializer=init),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=init),\n",
        "        ], name=\"critique\")\n",
        "    \n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        return self.critique(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8plw2BSFYrQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encode = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim, kernel_initializer=init), # no activation...\n",
        "        ], name=\"encode\")\n",
        "    \n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        mean, logvar = tf.split(self.encode(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.decode = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim)),\n",
        "\n",
        "            tf.keras.layers.Dense(units=7*7*256),\n",
        "            tf.keras.layers.Reshape(target_shape=(7, 7, 256)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=128, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=64, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=32, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=16, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", use_bias=False, kernel_initializer=init,\n",
        "                activation=\"tanh\"),\n",
        "        ], name=\"decode\")\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        return self.decode(x)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def reparameterize(mean, logvar):\n",
        "    # Logvar used for numerical stability\n",
        "    epsilon = tf.random.normal(shape=mean.shape)\n",
        "    return epsilon * tf.exp(logvar * .5) + mean\n",
        "\n",
        "@tf.function\n",
        "def generateImg(enc, dec, x):\n",
        "    mean, logvar = enc(x)\n",
        "    return generateDist(dec, mean, logvar)\n",
        "\n",
        "@tf.function\n",
        "def generateDist(dec, mean, logvar):\n",
        "    z = reparameterize(mean, logvar)\n",
        "    return dec(z)\n",
        "\n",
        "@tf.function\n",
        "def generatePrecise(enc, dec, x):\n",
        "    z, _ = enc(x)\n",
        "    return dec(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_UU3x3Vt8V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "prior = tfp.distributions.MultivariateNormalDiag(tf.zeros(latent_dim), tf.ones(latent_dim))\n",
        "N = tf.convert_to_tensor(IMG_HEIGHT * IMG_WIDTH, dtype=tf.float32)\n",
        "M = tf.convert_to_tensor(BATCH_SIZE, dtype=tf.float32)\n",
        "reconstructionMult = tf.math.divide(N, M)\n",
        "\n",
        "print(\"Reconstruction multiplier:\", end='\\t')\n",
        "tf.print(reconstructionMult)\n",
        "\n",
        "@tf.function\n",
        "def add_noise(x):\n",
        "    noise_intensity = 1.0\n",
        "    noise = tf.multiply(noise_intensity, tf.random.normal(shape=x.shape, mean=0.0, stddev=0.3))\n",
        "    return tf.clip_by_value(tf.add(x, noise), -1.0, 1.0)\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def compute_apply_gradients(enc, dec, crt, x, encOptimizer, decOptimizer, crtOptimizer, Wkl, Wrl, C):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        encLoss, decLoss, crtLoss = compute_loss(enc, dec, crt, x, Wkl, Wrl, C)\n",
        "\n",
        "    gradients_of_enc = tape.gradient(encLoss, enc.trainable_variables)\n",
        "    gradients_of_dec = tape.gradient(decLoss, dec.trainable_variables)\n",
        "    gradients_of_crt = tape.gradient(crtLoss, crt.trainable_variables)\n",
        "\n",
        "    encOptimizer.apply_gradients(zip(gradients_of_enc, enc.trainable_variables))\n",
        "    decOptimizer.apply_gradients(zip(gradients_of_dec, dec.trainable_variables))\n",
        "    crtOptimizer.apply_gradients(zip(gradients_of_crt, crt.trainable_variables))\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def compute_loss(enc, dec, crt, x, Wkl, Wrl, C, GANmode=True):\n",
        "    #Compute loss values\n",
        "    klLoss, recLoss, foolLoss, fooledLoss = compute_ALL_loss(enc, dec, crt, x)\n",
        "\n",
        "    # Group them up for each network\n",
        "    if GANmode:\n",
        "        outputLoss = tf.math.add(tf.math.multiply(Wrl, recLoss), foolLoss) # (Wrl * rl) + gl\n",
        "        encLoss = tf.math.add(\n",
        "            tf.math.multiply(Wkl, tf.math.abs(tf.math.subtract(klLoss, C))), # Wkl * |kl - C|\n",
        "            outputLoss)\n",
        "        decLoss = outputLoss\n",
        "        crtLoss = fooledLoss\n",
        "    else:\n",
        "        encLoss = tf.math.add(\n",
        "            tf.math.multiply(\n",
        "                Wkl, \n",
        "                tf.math.abs(tf.math.subtract(klLoss, C))), # Wkl * |kl - C|\n",
        "            recLoss)\n",
        "        decLoss = recLoss\n",
        "        crtLoss = fooledLoss\n",
        "\n",
        "    return encLoss, decLoss, crtLoss\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def compute_ALL_loss(enc, dec, crt, x):\n",
        "    mean, logvar = enc(x)\n",
        "\n",
        "    # KL Divergence Loss\n",
        "    posterior = tfp.distributions.MultivariateNormalDiag(mean, tf.exp(logvar * .5))\n",
        "    divergenceLoss = tf.reduce_mean(tfp.distributions.kl_divergence(posterior, prior))\n",
        "\n",
        "    # Reconstruction Loss (RMSE)\n",
        "    generated_images = generateDist(dec, mean, logvar)\n",
        "    reconstructionLoss = tf.math.multiply(reconstructionMult, tf.math.sqrt(tf.reduce_mean(tf.math.square(tf.math.subtract(x, generated_images)))))\n",
        "\n",
        "    real_scores = crt(x)    # May want to add noise?\n",
        "    fake_scores = crt(generated_images)\n",
        "    # samples = tf.random.normal(shape=[generated_images.shape[0], latent_dim])\n",
        "    # sample_scores = crt(dec(samples))\n",
        "    genGanLoss, crtGanLoss = compute_gan_loss(real_scores, fake_scores)#, sample_scores)\n",
        "\n",
        "    return divergenceLoss, reconstructionLoss, genGanLoss, crtGanLoss\n",
        "\n",
        "#@tf.function\n",
        "def compute_gan_loss(real_output, fake_output, sample_output=None):\n",
        "    dis_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.1)\n",
        "    gen_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    real_labels = tf.ones_like(real_output)\n",
        "    fake_labels = tf.zeros_like(fake_output)\n",
        "\n",
        "    # Loss from identitifation of real images\n",
        "    dis_real_loss = dis_cross_entropy(real_labels, real_output) # Try not to be fooled\n",
        "    \n",
        "    # Loss from identitifation of fake images\n",
        "    dis_fake_loss = dis_cross_entropy(fake_labels, fake_output) # Try not to be fooled\n",
        "    gen_fake_loss = gen_cross_entropy(real_labels, fake_output) # Try to fool\n",
        "    \n",
        "    if not sample_output is None:\n",
        "        # Loss from identitifation of fake sampled images\n",
        "        gen_sample_loss = gen_cross_entropy(real_labels, sample_output) # Try to fool\n",
        "        dis_sample_loss = dis_cross_entropy(fake_labels, sample_output) # Try not to be fooled\n",
        "\n",
        "        # For generator: FakeLoss + SampleLoss\n",
        "        gen_gan_loss = tf.math.add(gen_fake_loss, gen_sample_loss)\n",
        "        # For discriminator: RealLoss + FakeLoss + SampleLoss\n",
        "        dis_gan_loss = tf.math.add(tf.math.add(dis_real_loss, dis_fake_loss), dis_sample_loss)\n",
        "    else:\n",
        "        # For generator: FakeLoss\n",
        "        gen_gan_loss = gen_fake_loss\n",
        "        # For discriminator: RealLoss + FakeLoss\n",
        "        dis_gan_loss = tf.math.add(dis_real_loss, dis_fake_loss)\n",
        "    return gen_gan_loss, dis_gan_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag2zm_9h5w01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_StoicNet(prefix, full=False):\n",
        "    if prefix is None:\n",
        "        path_to_save = BASE_DIR + \"saved_model\"\n",
        "    else:\n",
        "        path_to_save = BASE_DIR + \"saved_model/{}\".format(prefix)\n",
        "    !mkdir -p \"{path_to_save}\"\n",
        "    print('Saving model at \"{}\"'.format(path_to_save))\n",
        "    if full:\n",
        "        encoder.save(path_to_save + \"/encoder.h5\")\n",
        "        decoder.save(path_to_save + \"/decoder.h5\")\n",
        "    else:\n",
        "        encoder.save_weights(path_to_save + \"/encoder.h5\")\n",
        "        decoder.save_weights(path_to_save + \"/decoder.h5\")\n",
        "\n",
        "\n",
        "def load_StoicNet(prefix):\n",
        "    if prefix is None:\n",
        "        path_to_save = BASE_DIR + \"saved_model\"\n",
        "    else:\n",
        "        path_to_save = BASE_DIR + \"saved_model/{}\".format(prefix)\n",
        "\n",
        "    encoder.load_weights(path_to_save + \"/encoder.h5\")\n",
        "    decoder.load_weights(path_to_save + \"/decoder.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCD9--NTt8WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(epoch, test_input):\n",
        "    imgs = decoder(test_input)\n",
        "    assert not np.any(np.isnan(imgs))\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    for i in range(imgs.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    fig.tight_layout()\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def display_novel_images():\n",
        "    for image_features in parsed_novel:\n",
        "        first = image_features['imageNeutral']\n",
        "        second = image_features['imageExpressive']\n",
        "        third = image_features['imageOther']\n",
        "        test_input = np.array([first, second, third])\n",
        "\n",
        "        images = generatePrecise(encoder, decoder, test_input[0:3])\n",
        "        ims = np.concatenate((test_input[0:3], images), axis=0)\n",
        "        assert not np.any(np.isnan(ims))\n",
        "        fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(6,4))\n",
        "        for i in range(ims.shape[0]):\n",
        "            c = i % 3\n",
        "            r = i // 3\n",
        "            axes[r, c].imshow(ims[i, :, :, 0], cmap='gray')\n",
        "            axes[r, c].set_yticklabels([])\n",
        "            axes[r, c].xaxis.set_visible(False)\n",
        "        axes[0,0].set_ylabel(\"Inputs\", size='large')\n",
        "        axes[1,0].set_ylabel(\"Generated\", size='large')\n",
        "        fig.tight_layout()\n",
        "        plt.savefig('novel_outputs.png')\n",
        "\n",
        "\n",
        "def display_imgs_ratings(test_input, epoch=-1):\n",
        "    images = generateImg(encoder, decoder, test_input[0:8])\n",
        "    ims = np.concatenate((test_input[0:8], images), axis=0)\n",
        "    assert not np.any(np.isnan(ims))\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=8, figsize=(11,4))\n",
        "    for i in range(ims.shape[0]):\n",
        "        c = i % 8\n",
        "        r = i // 8\n",
        "        axes[r, c].imshow(ims[i, :, :, 0], cmap='gray')\n",
        "        axes[r, c].set_yticklabels([])\n",
        "        axes[r, c].xaxis.set_visible(False)\n",
        "    axes[0,0].set_ylabel(\"Inputs\", size='large')\n",
        "    axes[1,0].set_ylabel(\"Generated\", size='large')\n",
        "    fig.tight_layout()\n",
        "    if epoch >= 0:\n",
        "        plt.savefig('gens_at_epoch_{:04d}.png'.format(epoch))\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_ALL_loss(ls):\n",
        "    kl, rl, gl, cl = zip(*ls)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.yaxis.tick_right()\n",
        "    plt.plot(kl, '-g', label='kL')\n",
        "    plt.plot(rl, '-b', label='rL')\n",
        "    plt.plot(gl, '-c', label='gL')\n",
        "    plt.plot(cl, '-r', label='cL')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_feature_changes():\n",
        "    steps = 15\n",
        "    magnitude = 3.0\n",
        "\n",
        "    # Build the feature vectors\n",
        "    independent_feature_vectors = np.zeros(shape=[steps*2+1, latent_dim, latent_dim])\n",
        "    for step in range(-1*steps, steps+1):\n",
        "        step_index = step + steps\n",
        "        mag = magnitude * (step/steps)\n",
        "        for feature_index in range(0, latent_dim):\n",
        "            independent_feature_vectors[step_index, feature_index, feature_index] = mag\n",
        "    \n",
        "    # Make the images\n",
        "    for step_index in range(0, steps*2+1):\n",
        "        print(\"Generating frame {}\".format(step_index))\n",
        "        encoding = independent_feature_vectors[step_index]\n",
        "        imgs = decoder(encoding)\n",
        "        assert not np.any(np.isnan(imgs))\n",
        "        fig = plt.figure(figsize=(10,10))\n",
        "        for i in range(imgs.shape[0]):\n",
        "            plt.subplot(10, 10, i+1)\n",
        "            plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "            plt.axis('off')\n",
        "        fig.tight_layout()\n",
        "        plt.savefig('frame_{0:03}.png'.format(step_index))\n",
        "        plt.close(fig)\n",
        "\n",
        "    # Make the animation\n",
        "    anim_filename = BASE_DIR + 'TrainingGifs/feature_changes_' + time.strftime('%l:%M_%b_%d') + '.gif'\n",
        "    print(\"Saving gif at: \" + anim_filename)\n",
        "    with imageio.get_writer(anim_filename, mode='I') as writer:\n",
        "        filenames = glob.glob('frame_*.png')\n",
        "        filenames = sorted(filenames)\n",
        "        filenames = filenames + filenames[::-1] # Go full circle\n",
        "        for i,filename in enumerate(filenames):\n",
        "            image = imageio.imread(filename)\n",
        "            writer.append_data(image)\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    print(\"Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXYOThHMQdx6",
        "colab_type": "text"
      },
      "source": [
        "# Training Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QH0nPiz0yVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 150\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "random_vector_for_generation = tf.random.normal(shape=[num_examples_to_generate, latent_dim])\n",
        "random_images_for_generation = [image_features['imageExpressive'] for image_features in parsed_CK_test.take(1)][0][0:num_examples_to_generate]\n",
        "\n",
        "encOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5)\n",
        "decOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5)\n",
        "crtOptimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.5)\n",
        "\n",
        "encoder = Encoder(latent_dim)\n",
        "decoder = Decoder(latent_dim)\n",
        "critic = Critic()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVDQ_wJVdezn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRESH = True\n",
        "if not FRESH:\n",
        "    load_StoicNet(\"TEMP_SAVE\")\n",
        "    startEpoch = 100\n",
        "    print(\"Training loaded model from epoch {}\".format(startEpoch))\n",
        "else:\n",
        "    print(\"Training a fresh model\")\n",
        "    startEpoch = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "jqNw-Wqht8WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Wkl (aka beta) weighs KL Divergence loss, limiting encoding capacity \n",
        "Wkl = tf.convert_to_tensor(1.0, dtype=tf.float32)\n",
        "max_Wkl = 1.0\n",
        "Wkl_ramp_start = 1   # Ramps up\n",
        "Wkl_ramp_end = 15\n",
        "\n",
        "# Wrl weighs reconstruction loss\n",
        "Wrl = tf.convert_to_tensor(0.5, dtype=tf.float32)\n",
        "max_Wrl = 1.0\n",
        "Wrl_ramp_start = 1   # Ramps up\n",
        "Wrl_ramp_end = 15\n",
        "\n",
        "# C adds capacity to the encoding\n",
        "C = tf.convert_to_tensor(0.0, dtype=tf.float32)     \n",
        "max_C = 20.0\n",
        "C_ramp_start = 60   # Ramps up\n",
        "C_ramp_end = 80\n",
        "\n",
        "#(Wkl,C) or (Wkl,Wrl,C)\n",
        "# Tried CK  (50, 0), (5,0), (5,~10), (~5,~25)\n",
        "# Tried LFW (~5,~25), (~3,~20), (~1,0), (~1,1,0), (,,)\n",
        "\n",
        "ls = []\n",
        "bestLoss = 999999.9\n",
        "start_time = time.time()\n",
        "for epoch in range(startEpoch, epochs):\n",
        "    # Train\n",
        "    print(\"\\nTraining\", end=\"\")\n",
        "    \n",
        "    batchCounter = 0\n",
        "    Wkl = min(max_Wkl, max_Wkl * (max(0, (epoch - Wkl_ramp_start)) / (Wkl_ramp_end - Wkl_ramp_start)))\n",
        "    Wkl = tf.convert_to_tensor(Wkl, dtype=tf.float32)\n",
        "    #C = min(max_C, max_C * (max(0, (epoch - C_ramp_start)) / (C_ramp_end-C_ramp_start)))\n",
        "    #C = tf.convert_to_tensor(C, dtype=tf.float32)\n",
        "\n",
        "    for image_features in parsed_LFW_train:\n",
        "        image_raw = image_features['image']\n",
        "\n",
        "        compute_apply_gradients(\n",
        "            encoder, decoder, critic,\n",
        "            image_raw,\n",
        "            encOptimizer, decOptimizer, crtOptimizer,\n",
        "            Wkl, Wrl, C)\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "    \n",
        "    # Test\n",
        "    print(\"\\nTesting\", end=\"\")\n",
        "    batchCounter = 0\n",
        "    kloss = tf.keras.metrics.Mean()\n",
        "    rloss = tf.keras.metrics.Mean()\n",
        "    gloss = tf.keras.metrics.Mean()\n",
        "    closs = tf.keras.metrics.Mean()\n",
        "    for image_features in parsed_LFW_test:\n",
        "        image_raw = image_features['image']\n",
        "\n",
        "        kl, rl, gl, cl = compute_ALL_loss(\n",
        "            encoder, decoder, critic,\n",
        "            image_raw)\n",
        "        \n",
        "        kloss(kl)\n",
        "        rloss(rl)\n",
        "        gloss(gl)\n",
        "        closs(cl)\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "\n",
        "    kl_base = kloss.result().numpy()\n",
        "    kl = tf.add(tf.math.multiply(kloss.result(), Wkl), C).numpy()\n",
        "    rl = tf.math.multiply(rloss.result(), Wrl).numpy()\n",
        "    gl = gloss.result().numpy()\n",
        "    cl = closs.result().numpy()\n",
        "    ls = ls + [(kl, rl, gl, cl)]\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    # Output\n",
        "    display.clear_output(wait=False)\n",
        "    print('Epoch {0}, Total epoch time {1:.1f}'.format(epoch, end_time-start_time))\n",
        "    print('Losses: k {0:.5f}({1:.1f}x{2:.5f}+{3:.1f})  r {4:.5f}  g {5:.5f}  c {6:.5f}'.format(\n",
        "            kl, Wkl, kl_base, C, rl, gl, cl))\n",
        "    plot_ALL_loss(ls)\n",
        "    display_imgs_ratings(random_images_for_generation)\n",
        "    #save_images(epoch, random_vector_for_generation)\n",
        "    display_novel_images()\n",
        "\n",
        "\n",
        "    # Save the model from time to time or if you get a new record (after sufficient training)\n",
        "    if epoch > 20 and kl + rl + gl < bestLoss:\n",
        "        bestLoss = kl + rl + gl\n",
        "        save_StoicNet(\"TEMP_BEST_MODEL\")\n",
        "        print(\"*Saved new best*\")\n",
        "    elif (epoch + 1) % 5 == 0:\n",
        "        save_StoicNet(\"TEMP_SAVE\")\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MyW7bvwStaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveName = \"FINAL_SAVE_\"+time.strftime('%l_%M_%b%d')\n",
        "save_StoicNet(saveName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxmHNJVTk1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_feature_changes()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1l2PxZpcsQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# anim_filename = BASE_DIR + 'TrainingGifs/vaegan' + time.strftime('%l:%M %b %d') + '.gif'\n",
        "# print(anim_filename)\n",
        "# with imageio.get_writer(anim_filename, mode='I') as writer:\n",
        "#     filenames = glob.glob('image_at_epoch_*.png')\n",
        "#     filenames = sorted(filenames)\n",
        "#     last = -1\n",
        "#     for i,filename in enumerate(filenames):\n",
        "#         frame = 2*(i**0.5)\n",
        "#         if round(frame) > round(last):\n",
        "#             last = frame\n",
        "#         else:\n",
        "#             continue\n",
        "#         image = imageio.imread(filename)\n",
        "#         writer.append_data(image)\n",
        "#     image = imageio.imread(filename)\n",
        "#     writer.append_data(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhpVx7DzQYuB",
        "colab_type": "text"
      },
      "source": [
        "# Testing Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4i_YSqdQYQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(latent_dim)\n",
        "decoder = Decoder(latent_dim)\n",
        "load_StoicNet(saveName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb_MvTfbRpW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_imgs_ratings(random_images_for_generation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irwxzovcnYum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_novel_images()\n",
        "print(encoder(test_input))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}