{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Trainer.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWEWOFA68xyU",
        "colab_type": "code",
        "outputId": "42f70dce-2e30-4f3d-c1da-c68354ea1fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"tf version {0} executing eagerly is {1}\".format(tf.__version__, tf.executing_eagerly()))\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "print(\"tfp version {0}\".format(tfp.__version__))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version 2.1.0 executing eagerly is True\n",
            "tfp version 0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P59ok20-3v4",
        "colab_type": "code",
        "outputId": "1c49820c-631a-4f0b-d676-2e0f0ab2434a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = '/content/drive/My Drive/StoicNetData/'"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNWxIsIK9KvO",
        "colab_type": "code",
        "outputId": "9e4e28a3-d075-4eec-b0ab-1ba8b37d2eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "print(\"Device name: \\\"{0}\\\"\".format(device_name))\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device name: \"/device:GPU:0\"\n",
            "Found GPU at: /device:GPU:0\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77kfnaVwt8Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import PIL\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('error', UserWarning)\n",
        "warnings.filterwarnings(\"error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFeV4R0mCQtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(98475651423)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FbVWr08t8Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 112\n",
        "IMG_WIDTH = 112\n",
        "\n",
        "keys_to_features = {\n",
        "    'image_neutral': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_expressive': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_other': tf.io.FixedLenFeature([], tf.string)\n",
        "}\n",
        "\n",
        "def parser(record):\n",
        "    parsed = tf.io.parse_single_example(record, keys_to_features)\n",
        "    \n",
        "    imageNeutral = tf.io.decode_raw(parsed[\"image_neutral\"], tf.uint8)\n",
        "    imageExpressive = tf.io.decode_raw(parsed[\"image_expressive\"], tf.uint8)\n",
        "    imageOther = tf.io.decode_raw(parsed[\"image_other\"], tf.uint8)\n",
        "    \n",
        "    imageNeutral = tf.cast(imageNeutral, tf.float32)\n",
        "    imageExpressive = tf.cast(imageExpressive, tf.float32)\n",
        "    imageOther = tf.cast(imageOther, tf.float32)\n",
        "    \n",
        "    imageNeutral = tf.reshape(imageNeutral, shape=[224,224,1])\n",
        "    imageExpressive = tf.reshape(imageExpressive, shape=[224,224,1])\n",
        "    imageOther = tf.reshape(imageOther, shape=[224,224,1])\n",
        "\n",
        "    imageNeutral = tf.image.resize(imageNeutral, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageExpressive = tf.image.resize(imageExpressive, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageOther = tf.image.resize(imageOther, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "\n",
        "    imageNeutral /= (255/2)\n",
        "    imageExpressive /= (255/2)\n",
        "    imageOther /= (255/2)\n",
        "    imageNeutral -= 1\n",
        "    imageExpressive -= 1\n",
        "    imageOther -= 1\n",
        "\n",
        "    return {\"imageNeutral\":imageNeutral, \"imageExpressive\":imageExpressive, \"imageOther\":imageOther}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtPS7faMt8V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "DB_PATH = BASE_DIR\n",
        "raw_train = tf.data.TFRecordDataset(DB_PATH + \"train.tfrecords\")\n",
        "raw_test = tf.data.TFRecordDataset(DB_PATH + \"test.tfrecords\")\n",
        "\n",
        "#raw_val = raw_test.shard(2,0)\n",
        "#raw_test = raw_test.shard(2,1)\n",
        "\n",
        "parsed_train = raw_train.map(parser).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "#parsed_val = raw_val.map(parser).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "parsed_test = raw_test.map(parser).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "latent_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yLaqmJVKt2A",
        "colab_type": "code",
        "outputId": "b79dbd78-d7c6-4354-c556-24856a883fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class Recognizer(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Recognizer, self).__init__()\n",
        "        self.encoder = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        " \n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim)\n",
        "        ], name=\"encoder\")\n",
        "\n",
        "        self.comparer = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim)),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ], name=\"comparer\")\n",
        "\n",
        "    \n",
        "    @tf.function\n",
        "    def recognize(self, a, b):\n",
        "        a_encoding = self.encode(a)\n",
        "        b_encoding = self.encode(b)\n",
        "\n",
        "        return self.decide(a_encoding, b_encoding)\n",
        "    \n",
        "    @tf.function\n",
        "    def encode(self, x):\n",
        "        encoding = self.encoder(x)\n",
        "        return encoding\n",
        "\n",
        "    @tf.function\n",
        "    def decide(self, a_enc, b_enc):\n",
        "        diffs = tf.abs(a_enc - b_enc)\n",
        "        prediction = self.comparer(diffs)\n",
        "        return prediction\n",
        "\n",
        "recognizer = Recognizer(latent_dim)\n",
        "recognizer.load_weights(BASE_DIR + 'saved_model/recognizerWeights')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f731afd1978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8plw2BSFYrQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim), # no activation...\n",
        "        ], name=\"encoder\")\n",
        "\n",
        "        self.generator = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim)),\n",
        "\n",
        "            tf.keras.layers.Dense(units=7*7*256),\n",
        "            tf.keras.layers.Reshape(target_shape=(7, 7, 256)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=128, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=64, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=32, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=16, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", use_bias=False,\n",
        "                activation=\"tanh\"),\n",
        "        ], name=\"generator\")\n",
        "\n",
        "    @tf.function\n",
        "    def encode(self, x):\n",
        "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "    @tf.function\n",
        "    def sample(self, epsilon=None):\n",
        "        if epsilon is None:\n",
        "            epsilon = tf.random.normal(shape=(100, self.latent_dim))\n",
        "        return self.decode(epsilon, apply_sigmoid=True)\n",
        "    \n",
        "    @tf.function\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        # Logvar used for numerical stability\n",
        "        epsilon = tf.random.normal(shape=mean.shape)\n",
        "        return epsilon * tf.exp(logvar * .5) + mean\n",
        "\n",
        "    @tf.function\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "        logits = self.generator(z)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "        return logits\n",
        "    \n",
        "    @tf.function\n",
        "    def generateDist(self, mean, logvar):\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        return self.generateZ(z)\n",
        "\n",
        "    @tf.function\n",
        "    def generateZ(self, z):\n",
        "        x_logit = self.decode(z)\n",
        "        return x_logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh5R2MOXcA21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def generateImg(x):\n",
        "    mean, logvar = vae.encode(x)\n",
        "    return vae.generateDist(mean, logvar)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqv0Zi6T8lgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.discriminator = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(512),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "        ], name=\"discriminator\")\n",
        "    \n",
        "    @tf.function\n",
        "    def decide(self, x):\n",
        "        return self.discriminator(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_UU3x3Vt8V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam( learning_rate=0.0001, beta_1=0.5)\n",
        "\n",
        "prior = tfp.distributions.MultivariateNormalDiag(tf.zeros(latent_dim), tf.ones(latent_dim))\n",
        "alpha = tf.convert_to_tensor(0.2, dtype=tf.float32)\n",
        "\n",
        "@tf.function\n",
        "def compute_apply_gradients(vae, dis, x_neutral, x_express, x_other, vaeOptimizer, disOptimizer, beta):\n",
        "    # Watch any trainable variables for automatic differentiation\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        vloss, dloss = compute_loss(vae, dis, x_neutral, x_express, x_other, beta)\n",
        "\n",
        "    if beta >= 1.0:\n",
        "        if vloss >= 5 * dloss:\n",
        "            gradients_of_vae = tape.gradient(vloss, vae.trainable_variables)\n",
        "            vaeOptimizer.apply_gradients(zip(gradients_of_vae, vae.trainable_variables))\n",
        "            return 1.0\n",
        "        if vloss < dloss:\n",
        "            gradients_of_discriminator = tape.gradient(dloss, dis.trainable_variables)\n",
        "            disOptimizer.apply_gradients(zip(gradients_of_discriminator, dis.trainable_variables))\n",
        "            return 0.0\n",
        "        else:\n",
        "            gradients_of_vae = tape.gradient(vloss, vae.trainable_variables)\n",
        "            gradients_of_discriminator = tape.gradient(dloss, dis.trainable_variables)\n",
        "            vaeOptimizer.apply_gradients(zip(gradients_of_vae, vae.trainable_variables))\n",
        "            disOptimizer.apply_gradients(zip(gradients_of_discriminator, dis.trainable_variables))\n",
        "            return 0.5\n",
        "    else:\n",
        "        gradients_of_vae = tape.gradient(vloss, vae.trainable_variables)\n",
        "        gradients_of_discriminator = tape.gradient(dloss, dis.trainable_variables)\n",
        "        vaeOptimizer.apply_gradients(zip(gradients_of_vae, vae.trainable_variables))\n",
        "        disOptimizer.apply_gradients(zip(gradients_of_discriminator, dis.trainable_variables))\n",
        "        return 0.5\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_loss(vae, dis, x_neutral, x_express, x_other, beta):\n",
        "    mean_e, logvar_e = vae.encode(x_express)\n",
        "    if beta < 0.5:\n",
        "        # Just be an auto-encoder to warm up\n",
        "        generated_images = vae.generateZ(mean_e)\n",
        "    else:\n",
        "        # Now let's get variational up in here\n",
        "        generated_images = vae.generateDist(mean_e, logvar_e)\n",
        "    \n",
        "    # Let the discriminator discriminate\n",
        "    real_decisions = dis.decide(x_neutral)\n",
        "    fake_decisions = dis.decide(generated_images)\n",
        "\n",
        "    # Compute all the losses\n",
        "    dloss = discriminator_loss(real_decisions, fake_decisions)\n",
        "    vloss = vae_loss(x_express, generated_images, fake_decisions, mean_e, logvar_e, beta)\n",
        "    return vloss, dloss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_ALL_loss(vae, dis, x_neutral, x_express, x_other, beta):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "    mean_e, logvar_e = vae.encode(x_express)\n",
        "    if beta < 0.5:\n",
        "        # Just be an auto-encoder to warm up\n",
        "        generated_images = vae.generateZ(mean_e)\n",
        "    else:\n",
        "        # Now let's get variational up in here\n",
        "        generated_images = vae.generateDist(mean_e, logvar_e)\n",
        "    \n",
        "    # Let the discriminator discriminate\n",
        "    real_decisions = dis.decide(x_neutral)\n",
        "    fake_decisions = dis.decide(generated_images)\n",
        "\n",
        "\n",
        "    # Loss from failing to identify real images\n",
        "    real_labels = tf.ones_like(real_decisions)\n",
        "    real_loss = cross_entropy(real_labels, real_decisions)\n",
        "    \n",
        "    # Loss from failing to identify fake images\n",
        "    fake_labels = tf.zeros_like(fake_decisions)\n",
        "    fake_loss = cross_entropy(fake_labels, fake_decisions)\n",
        "    \n",
        "    # RealLoss + FakeLoss\n",
        "    dloss = tf.math.add(real_loss, fake_loss)\n",
        "\n",
        "\n",
        "    # Loss from not preserving identity\n",
        "    identityScores = recognizer.recognize(x_express, generated_images)\n",
        "    identityLoss = cross_entropy(tf.ones_like(identityScores), identityScores)\n",
        "\n",
        "    # Loss from not fooling the discriminator\n",
        "    detectionLoss = cross_entropy(tf.ones_like(fake_decisions), fake_decisions)\n",
        "\n",
        "    # KL Divergence Loss\n",
        "    posterior = tfp.distributions.MultivariateNormalDiag(mean_e, logvar_e)\n",
        "    divergenceLoss = tfp.distributions.kl_divergence(posterior, prior)\n",
        "\n",
        "    # IdentityLoss + DetectionLoss + (Beta * DivergenceLoss)\n",
        "    return identityLoss, detectionLoss, divergenceLoss, dloss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    \n",
        "    # Loss from failing to identify real images\n",
        "    real_labels = tf.ones_like(real_output)\n",
        "    real_loss = cross_entropy(real_labels, real_output)\n",
        "    \n",
        "    # Loss from failing to identify fake images\n",
        "    fake_labels = tf.zeros_like(fake_output)\n",
        "    fake_loss = cross_entropy(fake_labels, fake_output)\n",
        "    \n",
        "    # RealLoss + FakeLoss\n",
        "    return tf.math.add(real_loss, fake_loss)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def vae_loss(x_express, output_images, output_decisions, mean_e, logvar_e, beta):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "    # Loss from not preserving identity\n",
        "    identityScores = recognizer.recognize(x_express, output_images)\n",
        "    identityLoss = cross_entropy(tf.ones_like(identityScores), identityScores)\n",
        "\n",
        "    # Loss from not fooling the discriminator\n",
        "    detectionLoss = cross_entropy(tf.ones_like(output_decisions), output_decisions)\n",
        "\n",
        "    # KL Divergence Loss\n",
        "    posterior = tfp.distributions.MultivariateNormalDiag(mean_e, logvar_e)\n",
        "    divergenceLoss = tf.reduce_mean(tfp.distributions.kl_divergence(posterior, prior))\n",
        "\n",
        "    # IdentityLoss + DetectionLoss + (Beta * DivergenceLoss)\n",
        "    return tf.math.add(tf.math.add(identityLoss, detectionLoss), tf.math.multiply(beta, divergenceLoss))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3qJfbC8pt8WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 200\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "random_vector_for_generation = tf.random.normal(shape=[num_examples_to_generate, latent_dim])\n",
        "random_images_for_generation = [image_features['imageExpressive'] for image_features in parsed_test.take(1)][0][0:num_examples_to_generate]\n",
        "\n",
        "vae = VAE(100)\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag2zm_9h5w01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup checkpoint stuff\n",
        "checkpoint_dir = BASE_DIR + 'training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(vae_optimizer=vae_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 vae=vae,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCD9--NTt8WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(epoch, test_input):\n",
        "    imgs = vae.sample(test_input)\n",
        "    assert not np.any(np.isnan(imgs))\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    ds = discriminator.decide(imgs)\n",
        "    for i in range(imgs.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.gca().set_title(\"{0:.4f}\".format(ds[i,0]))\n",
        "        plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    fig.tight_layout()\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.close(fig)\n",
        "\n",
        "def display_discrim_images(imgs, dis):\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    ds = discriminator.decide(imgs)\n",
        "    for i in range(imgs.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.gca().set_title(\"{0:.4f}\".format(ds[i,0]))\n",
        "        plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def display_imgs_ratings(test_input, data, epoch=-1):\n",
        "    images = generateImg(test_input[0:8])\n",
        "    rs = recognizer.recognize(test_input[0:8], images)\n",
        "    for features in data:\n",
        "        expressive = features['imageExpressive']\n",
        "        neutral = features['imageNeutral']\n",
        "    ims = np.concatenate((test_input[0:8], images, neutral[0:8], expressive[0:8]), axis=0)\n",
        "    fig, axes = plt.subplots(nrows=4, ncols=8, figsize=(11,6))\n",
        "    ds = discriminator.decide(ims)\n",
        "    for i in range(ims.shape[0]):\n",
        "        c = i % 8\n",
        "        r = i // 8\n",
        "        if r == 1:\n",
        "            axes[r, c].set_title(\"d{0:.6f}\\nr{1:.4f}\".format(ds[i,0], rs[c,0]))\n",
        "        else: \n",
        "            axes[r, c].set_title(\"d{0:.6f}\".format(ds[i,0]))\n",
        "        axes[r, c].imshow(ims[i, :, :, 0], cmap='gray')\n",
        "        axes[r, c].set_yticklabels([])\n",
        "        axes[r, c].xaxis.set_visible(False)\n",
        "    axes[0,0].set_ylabel(\"Inputs\", size='large')\n",
        "    axes[1,0].set_ylabel(\"Generated\", size='large')\n",
        "    axes[2,0].set_ylabel(\"Neutral*\", size='large')\n",
        "    axes[3,0].set_ylabel(\"Expressive\", size='large')\n",
        "    fig.tight_layout()\n",
        "    if epoch >= 0:\n",
        "        plt.savefig('gens_ratings_at_epoch_{:04d}.png'.format(epoch))\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "def plot_GAN_loss(ls):\n",
        "    vl, dl = zip(*ls)\n",
        "    fig = plt.figure()\n",
        "    plt.plot(vl, 'g', label='Lv')\n",
        "    plt.plot(dl, 'r', label='Ld')\n",
        "    plt.title(\"VAE (Lv) and Discriminator (Ld) Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_ALL_loss(ls):\n",
        "    il, fl, kl, dl = zip(*ls)\n",
        "    fig = plt.figure()\n",
        "    plt.plot(il, '-og', label='Lv_i')\n",
        "    plt.plot(fl, '-oy', label='Lv_f')\n",
        "    plt.plot(kl, '-ob', label='Lv_k')\n",
        "    plt.plot(dl, '-or', label='Ld')\n",
        "    plt.title(\"VAE (Lv) and Discriminator (Ld) Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "jqNw-Wqht8WG",
        "colab_type": "code",
        "outputId": "27043c3b-b1f9-495a-ef6f-f4d7cb0794ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Save image for pre-training\n",
        "max_beta = 1\n",
        "beta = 0\n",
        "ramp_end = 10\n",
        "\n",
        "genBatches = 0\n",
        "totalBatches = 0\n",
        "ls = []\n",
        "start_time = end_time = 0\n",
        "for epoch in range(0, epochs):\n",
        "\n",
        "    # Train\n",
        "    print(\"\\nTraining\", end=\"\")\n",
        "    start_time = time.time()\n",
        "    batchCounter = 0\n",
        "    beta = min(max_beta, max_beta * (epoch / ramp_end))\n",
        "    beta = tf.convert_to_tensor(beta, dtype=tf.float32)\n",
        "    for image_features in parsed_train:\n",
        "        neutral_raw = image_features['imageNeutral']\n",
        "        assert not np.any(np.isnan(neutral_raw))\n",
        "        expressive_raw = image_features['imageExpressive']\n",
        "        assert not np.any(np.isnan(expressive_raw))\n",
        "        other_raw = image_features['imageOther']\n",
        "        assert not np.any(np.isnan(other_raw))\n",
        "\n",
        "        genBatches += compute_apply_gradients(\n",
        "            vae, discriminator,\n",
        "            neutral_raw, expressive_raw, other_raw,\n",
        "            vae_optimizer, discriminator_optimizer,\n",
        "            beta)\n",
        "\n",
        "        totalBatches += 1\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "    \n",
        "    # Test\n",
        "    print(\"\\nTesting\", end=\"\")\n",
        "    batchCounter = 0\n",
        "    iloss = tf.keras.metrics.Mean()\n",
        "    floss = tf.keras.metrics.Mean()\n",
        "    kloss = tf.keras.metrics.Mean()\n",
        "    dloss = tf.keras.metrics.Mean()\n",
        "    for image_features in parsed_test:\n",
        "        neutral_raw = image_features['imageNeutral']\n",
        "        expressive_raw = image_features['imageExpressive']\n",
        "        other_raw = image_features['imageOther']\n",
        "\n",
        "        il, fl, kl, dl = compute_ALL_loss(vae, discriminator,\n",
        "                                          neutral_raw, expressive_raw, other_raw,\n",
        "                                          beta)\n",
        "        iloss(il)\n",
        "        floss(fl)\n",
        "        kloss(kl)\n",
        "        dloss(dl)\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "\n",
        "    il = iloss.result()\n",
        "    fl = floss.result()\n",
        "    kl = beta * kloss.result()\n",
        "    dl = dloss.result()\n",
        "    ls = ls + [(il, fl, kl, dl)]\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    # Output\n",
        "    display.clear_output(wait=False)\n",
        "    print('Epoch {0}, VAE Loss {1}, Disc Loss {2}\\n'\n",
        "        'BatchRatio {3}, Total epoch time {4:.1f}'.format(\n",
        "            epoch, (il.numpy(), fl.numpy(), kl.numpy()), dl, genBatches.numpy() / totalBatches, end_time - start_time))\n",
        "    print(\"Beta: {0}\".format(beta))\n",
        "    display_imgs_ratings(random_images_for_generation, parsed_test.take(1))    \n",
        "    save_images(epoch, random_vector_for_generation)\n",
        "    #plot_GAN_loss(ls)\n",
        "    plot_ALL_loss(ls)\n",
        "\n",
        "    # Save the model from time to time\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        display_imgs_ratings(random_images_for_generation, parsed_test.take(1), epoch)\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 25, VAE Loss (0.7532266, 1.5064958, 1.0437334), Disc Loss 0.5794945955276489\n",
            "BatchRatio 0.7453665737247827, Total epoch time 74.0\n",
            "Beta: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MyW7bvwStaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"FINAL_CKPT_\" + time.strftime('%l:%M%b%d'))\n",
        "checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1l2PxZpcsQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anim_filename = BASE_DIR + 'TrainingGifs/vaegan' + time.strftime('%l:%M %b %d') + '.gif'\n",
        "print(anim_filename)\n",
        "with imageio.get_writer(anim_filename, mode='I') as writer:\n",
        "    filenames = glob.glob('image_at_epoch_*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    last = -1\n",
        "    for i,filename in enumerate(filenames):\n",
        "        frame = 2*(i**0.5)\n",
        "        if round(frame) > round(last):\n",
        "            last = frame\n",
        "        else:\n",
        "            continue\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zldkzCEdT1Rq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_GAN_loss(ls)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}