{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Trainer.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWEWOFA68xyU",
        "colab_type": "code",
        "outputId": "aca8dd15-a4d4-4fae-97e5-b067fd3b2b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"tf version {0} executing eagerly is {1}\".format(tf.__version__, tf.executing_eagerly()))\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "print(\"tfp version {0}\".format(tfp.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "tf version 2.1.0 executing eagerly is True\n",
            "tfp version 0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P59ok20-3v4",
        "colab_type": "code",
        "outputId": "4ba04c25-8699-40f4-e59a-afd9ce159150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = '/content/drive/My Drive/StoicNetData/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNWxIsIK9KvO",
        "colab_type": "code",
        "outputId": "e3c8ac39-7e65-4bf8-dc74-095ced7828c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "print(\"Device name: \\\"{0}\\\"\".format(device_name))\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device name: \"/device:GPU:0\"\n",
            "Found GPU at: /device:GPU:0\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77kfnaVwt8Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import PIL\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('error', UserWarning)\n",
        "warnings.filterwarnings(\"error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFeV4R0mCQtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(98475651423)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FbVWr08t8Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 112\n",
        "IMG_WIDTH = 112\n",
        "\n",
        "keys_to_features = {\n",
        "    'image_neutral': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_expressive': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_other': tf.io.FixedLenFeature([], tf.string)\n",
        "}\n",
        "\n",
        "def parser(record):\n",
        "    parsed = tf.io.parse_single_example(record, keys_to_features)\n",
        "    \n",
        "    imageNeutral = tf.io.decode_raw(parsed[\"image_neutral\"], tf.uint8)\n",
        "    imageExpressive = tf.io.decode_raw(parsed[\"image_expressive\"], tf.uint8)\n",
        "    imageOther = tf.io.decode_raw(parsed[\"image_other\"], tf.uint8)\n",
        "    \n",
        "    imageNeutral = tf.cast(imageNeutral, tf.float32)\n",
        "    imageExpressive = tf.cast(imageExpressive, tf.float32)\n",
        "    imageOther = tf.cast(imageOther, tf.float32)\n",
        "    \n",
        "    imageNeutral = tf.reshape(imageNeutral, shape=[224,224,1])\n",
        "    imageExpressive = tf.reshape(imageExpressive, shape=[224,224,1])\n",
        "    imageOther = tf.reshape(imageOther, shape=[224,224,1])\n",
        "\n",
        "    imageNeutral = tf.image.resize(imageNeutral, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageExpressive = tf.image.resize(imageExpressive, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageOther = tf.image.resize(imageOther, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "\n",
        "    imageNeutral /= (255/2)\n",
        "    imageExpressive /= (255/2)\n",
        "    imageOther /= (255/2)\n",
        "    imageNeutral -= 1\n",
        "    imageExpressive -= 1\n",
        "    imageOther -= 1\n",
        "\n",
        "    return {\"imageNeutral\":imageNeutral, \"imageExpressive\":imageExpressive, \"imageOther\":imageOther}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtPS7faMt8V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "DB_PATH = BASE_DIR\n",
        "raw_train = tf.data.TFRecordDataset(DB_PATH + \"train.tfrecords\")\n",
        "raw_test = tf.data.TFRecordDataset(DB_PATH + \"test.tfrecords\")\n",
        "\n",
        "raw_novel = tf.data.TFRecordDataset(DB_PATH + \"novel.tfrecords\")\n",
        "parsed_novel = raw_novel.map(parser)\n",
        "\n",
        "#raw_val = raw_test.shard(2,0)\n",
        "#raw_test = raw_test.shard(2,1)\n",
        "\n",
        "parsed_train = raw_train.map(parser).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "#parsed_val = raw_val.map(parser).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "parsed_test = raw_test.map(parser).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "latent_dim = 64 #100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yLaqmJVKt2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recognizer(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Recognizer, self).__init__()\n",
        "        self.encoder = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        " \n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim)\n",
        "        ], name=\"encoder\")\n",
        "\n",
        "        self.comparer = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim)),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ], name=\"comparer\")\n",
        "\n",
        "    \n",
        "    @tf.function\n",
        "    def recognize(self, a, b):\n",
        "        a_encoding = self.encode(a)\n",
        "        b_encoding = self.encode(b)\n",
        "\n",
        "        return self.decide(a_encoding, b_encoding)\n",
        "    \n",
        "    @tf.function\n",
        "    def encode(self, x):\n",
        "        encoding = self.encoder(x)\n",
        "        return encoding\n",
        "\n",
        "    @tf.function\n",
        "    def decide(self, a_enc, b_enc):\n",
        "        diffs = tf.abs(a_enc - b_enc)\n",
        "        prediction = self.comparer(diffs)\n",
        "        return prediction\n",
        "\n",
        "recognizer = Recognizer(latent_dim)\n",
        "# Start with the mostly pretrained model?\n",
        "#recognizer.load_weights(BASE_DIR + 'saved_model/recognizerWeights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8plw2BSFYrQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.random_normal_initializer(mean=0.0, stddev=0.02, seed=918273645)\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encode = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim, kernel_initializer=init), # no activation...\n",
        "        ], name=\"encode\")\n",
        "    \n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        mean, logvar = tf.split(self.encode(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.decode = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim)),\n",
        "\n",
        "            tf.keras.layers.Dense(units=7*7*256),\n",
        "            tf.keras.layers.Reshape(target_shape=(7, 7, 256)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=128, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=64, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=32, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=16, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", use_bias=False, kernel_initializer=init,\n",
        "                activation=\"tanh\"),\n",
        "        ], name=\"decode\")\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        return self.decode(x)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def reparameterize(mean, logvar):\n",
        "    # Logvar used for numerical stability\n",
        "    epsilon = tf.random.normal(shape=mean.shape)\n",
        "    return epsilon * tf.exp(logvar * .5) + mean\n",
        "\n",
        "@tf.function\n",
        "def generateImg(enc, dec, x):\n",
        "    mean, logvar = enc(x)\n",
        "    return generateDist(dec, mean, logvar)\n",
        "\n",
        "@tf.function\n",
        "def generateDist(dec, mean, logvar):\n",
        "    z = reparameterize(mean, logvar)\n",
        "    return dec(z)\n",
        "\n",
        "@tf.function\n",
        "def generatePrecise(enc, dec, x):\n",
        "    z, _ = enc(x)\n",
        "    return dec(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqv0Zi6T8lgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.discriminate = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(512, kernel_initializer=init),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=init),\n",
        "        ], name=\"discriminate\")\n",
        "    \n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        return self.discriminate(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_UU3x3Vt8V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QuadrupletLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, alpha):\n",
        "        super(QuadrupletLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # anchor         positive         negative         generated negative\n",
        "        anc = y_pred[0]; pos = y_pred[1]; neg = y_pred[2]; gneg = y_pred[3]\n",
        "        \n",
        "        # typically use tf.reduce_sum(tf.square(tf.subtract(\n",
        "        # but some papers have suggested not squaring.\n",
        "\n",
        "        # distance between the anchor and the positive\n",
        "        anc_pos_dist = tf.reduce_sum(tf.subtract(anc, pos), axis=-1)    \n",
        "        # distance between the anchor and the negative\n",
        "        anc_neg_dist = tf.reduce_sum(tf.subtract(anc, neg), axis=-1)\n",
        "        # distance between the anchor and the generated negative\n",
        "        anc_gneg_dist = tf.reduce_sum(tf.subtract(anc, gneg), axis=-1)\n",
        "        \n",
        "        trip_pos_neg = tf.math.maximum(tf.add(tf.subtract(anc_pos_dist, anc_neg_dist), self.alpha), 0.0)\n",
        "        trip_pos_gneg = tf.math.maximum(tf.add(tf.subtract(anc_pos_dist, anc_gneg_dist), self.alpha), 0.0)\n",
        "\n",
        "        return tf.add(trip_pos_neg, trip_pos_gneg)\n",
        "\n",
        "encOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.5)\n",
        "decOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.5)\n",
        "disOptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n",
        "idenOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00006, beta_1=0.5)\n",
        "\n",
        "prior = tfp.distributions.MultivariateNormalDiag(tf.zeros(latent_dim), tf.ones(latent_dim))\n",
        "N = tf.convert_to_tensor(IMG_HEIGHT * IMG_WIDTH, dtype=tf.float32)\n",
        "M = tf.convert_to_tensor(BATCH_SIZE, dtype=tf.float32)\n",
        "reconstructionMult = tf.math.divide(N, M)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_apply_gradients(enc, dec, dis, iden, x_neutral, x_express, x_other, encOptimizer, decOptimizer, disOptimizer, idenOptimizer, alpha, beta, gammaD, gammaE):\n",
        "    # Watch any trainable variables for automatic differentiation\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        encloss, decloss, disloss, idenloss = compute_loss(enc, dec, dis, iden,\n",
        "                                                           x_neutral, x_express, x_other,\n",
        "                                                           alpha, beta, gammaD, gammaE)\n",
        "\n",
        "    gradients_of_enc = tape.gradient(encloss, enc.trainable_variables)\n",
        "    gradients_of_dec = tape.gradient(decloss, dec.trainable_variables)\n",
        "    gradients_of_dis = tape.gradient(disloss, dis.trainable_variables)\n",
        "    gradients_of_iden = tape.gradient(idenloss, iden.trainable_variables)\n",
        "\n",
        "    encOptimizer.apply_gradients(zip(gradients_of_enc, enc.trainable_variables))\n",
        "    decOptimizer.apply_gradients(zip(gradients_of_dec, dec.trainable_variables))\n",
        "    disOptimizer.apply_gradients(zip(gradients_of_dis, dis.trainable_variables))\n",
        "    idenOptimizer.apply_gradients(zip(gradients_of_iden, iden.trainable_variables))\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def compute_loss(enc, dec, dis, iden, x_neutral, x_express, x_other, alpha, beta, gammaD, gammaE):\n",
        "    #Compute loss values\n",
        "    klLoss, recLoss, decGanLoss, disGanLoss, presLoss, idenLoss = compute_ALL_loss(enc, dec, dis, iden,\n",
        "                                                                                   x_neutral, x_express, x_other)\n",
        "\n",
        "    presLoss  = tf.math.multiply(alpha, presLoss)\n",
        "\n",
        "    # Group them up for each network\n",
        "    encLoss = tf.math.add(\n",
        "        tf.math.add(\n",
        "            tf.math.multiply(beta,  klLoss),\n",
        "            tf.math.multiply(gammaE, recLoss)),\n",
        "        presLoss) # (B * Lkl) + Lr + (A*Lp)\n",
        "    decLoss = tf.math.add(\n",
        "        tf.math.add(\n",
        "            tf.math.multiply(gammaD, recLoss),\n",
        "            decGanLoss),\n",
        "        presLoss) # (G * Lr) - Lg + (A*Lp)\n",
        "    disLoss = disGanLoss\n",
        "    idenLoss = idenLoss\n",
        "\n",
        "    return encLoss, decLoss, disLoss, idenLoss\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def compute_ALL_loss(enc, dec, dis, iden, x_neutral, x_express, x_other):\n",
        "    mean_e, logvar_e = enc(x_express)\n",
        "\n",
        "    # KL Divergence Loss\n",
        "    posterior = tfp.distributions.MultivariateNormalDiag(mean_e, tf.exp(logvar_e * .5))\n",
        "    divergenceLoss = tf.reduce_mean(tfp.distributions.kl_divergence(posterior, prior))\n",
        "\n",
        "    generated_images = generateDist(dec, mean_e, logvar_e)\n",
        "    generated_images_precise = dec(mean_e)\n",
        "\n",
        "    # Reconstruction Loss\n",
        "    reconstructionLoss = tf.math.multiply(reconstructionMult, tf.math.sqrt(tf.reduce_mean(tf.math.square(tf.math.subtract(x_neutral, generated_images_precise)))))\n",
        "\n",
        "    # Let the discriminator discriminate\n",
        "    real_decisions = dis(x_neutral)\n",
        "    fake_decisions = dis(generated_images)\n",
        "    #samples = tf.random.normal(shape=[generated_images.shape[0], latent_dim])\n",
        "    #sample_decisions = dis(dec(samples))\n",
        "\n",
        "    # Discriminator-based Loss\n",
        "    genGanLoss, disGanLoss = compute_gan_loss(real_decisions, fake_decisions)#, sample_decisions)\n",
        "\n",
        "    # VAE loss from not preserving identity\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    presScores = iden.recognize(x_express, generated_images)\n",
        "    preserveLoss = cross_entropy(tf.ones_like(presScores), presScores)\n",
        "\n",
        "    # Loss for the identity recognition network\n",
        "    identityLoss = compute_id_loss(iden, x_neutral, x_express, x_other, generated_images_precise)\n",
        "\n",
        "    return divergenceLoss, reconstructionLoss, genGanLoss, disGanLoss, preserveLoss, identityLoss\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def compute_gan_loss(real_output, fake_output, sample_output=None):\n",
        "    dis_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0.1)\n",
        "    gen_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    real_labels = tf.ones_like(real_output)\n",
        "    fake_labels = tf.zeros_like(fake_output)\n",
        "\n",
        "    # Loss from identitifation of real images\n",
        "    dis_real_loss = dis_cross_entropy(real_labels, real_output) # Try not to be fooled\n",
        "    \n",
        "    # Loss from identitifation of fake images\n",
        "    dis_fake_loss = dis_cross_entropy(fake_labels, fake_output) # Try not to be fooled\n",
        "    gen_fake_loss = gen_cross_entropy(real_labels, fake_output) # Try to fool\n",
        "    \n",
        "    if not sample_output is None:\n",
        "        # Loss from identitifation of fake sampled images\n",
        "        gen_sample_loss = gen_cross_entropy(real_labels, sample_output) # Try to fool\n",
        "        dis_sample_loss = dis_cross_entropy(fake_labels, sample_output) # Try not to be fooled\n",
        "    \n",
        "    if not sample_output is None:\n",
        "        # For generator: FakeLoss + SampleLoss\n",
        "        gen_gan_loss = tf.math.add(gen_fake_loss, gen_sample_loss)\n",
        "        # For discriminator: RealLoss + FakeLoss + SampleLoss\n",
        "        dis_gan_loss = tf.math.add(tf.math.add(dis_real_loss, dis_fake_loss), dis_sample_loss)\n",
        "    else:\n",
        "        # For generator: FakeLoss\n",
        "        gen_gan_loss = gen_fake_loss\n",
        "        # For discriminator: RealLoss + FakeLoss\n",
        "        dis_gan_loss = tf.math.add(dis_real_loss, dis_fake_loss)\n",
        "    return gen_gan_loss, dis_gan_loss\n",
        "\n",
        "\n",
        "def compute_id_loss(iden, x_neutral, x_express, x_other, x_gen):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    quadruplet_loss = QuadrupletLoss(tf.convert_to_tensor(0.2, dtype=tf.float32))\n",
        "\n",
        "    e_neutral = iden.encode(tf.convert_to_tensor(x_neutral, tf.float32))\n",
        "    e_express = iden.encode(tf.convert_to_tensor(x_express, tf.float32))\n",
        "    e_other = iden.encode(tf.convert_to_tensor(x_other, tf.float32))\n",
        "    e_gen = iden.encode(tf.convert_to_tensor(x_gen, tf.float32))\n",
        "\n",
        "    # Encoding losses\n",
        "    ql = quadruplet_loss([], [e_express, e_neutral, e_other, e_gen])\n",
        "\n",
        "    # Prediction losses\n",
        "    pos_preds = iden.decide(e_neutral, e_express)   # anchor, positive\n",
        "    neg_preds = iden.decide(e_neutral, e_other)     # anchor, negative\n",
        "    gen_preds = iden.decide(e_neutral, e_gen)       # anchor, gen. neg.\n",
        "    \n",
        "    pos_labels = tf.ones_like(pos_preds)\n",
        "    neg_labels = tf.zeros_like(neg_preds)\n",
        "\n",
        "    pos_loss = cross_entropy(pos_labels, pos_preds)\n",
        "    neg_loss = cross_entropy(neg_labels, neg_preds)\n",
        "    gen_loss = cross_entropy(neg_labels, gen_preds)\n",
        "\n",
        "    return ql + (pos_loss + neg_loss + gen_loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3qJfbC8pt8WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 150\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "random_vector_for_generation = tf.random.normal(shape=[num_examples_to_generate, latent_dim])\n",
        "random_images_for_generation = [image_features['imageExpressive'] for image_features in parsed_test.take(1)][0][0:num_examples_to_generate]\n",
        "\n",
        "encoder = Encoder(latent_dim)\n",
        "decoder = Decoder(latent_dim)\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag2zm_9h5w01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup checkpoint stuff\n",
        "checkpoint_dir = BASE_DIR + 'training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckptEpoch{}\")\n",
        "checkpoint = tf.train.Checkpoint(encOptimizer=encOptimizer,\n",
        "                                 decOptimizer=decOptimizer,\n",
        "                                 disOptimizer=disOptimizer,\n",
        "                                 idenOptimizer=idenOptimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder,\n",
        "                                 discriminator=discriminator,\n",
        "                                 recognizer=recognizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCD9--NTt8WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(epoch, test_input):\n",
        "    imgs = decoder(test_input)\n",
        "    assert not np.any(np.isnan(imgs))\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    ds = discriminator(imgs)\n",
        "    for i in range(imgs.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.gca().set_title(\"{0:.4f}\".format(ds[i,0]))\n",
        "        plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    fig.tight_layout()\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    #plt.close(fig)\n",
        "\n",
        "def display_novel_images():\n",
        "    for image_features in parsed_novel:\n",
        "        first = image_features['imageNeutral']\n",
        "        second = image_features['imageExpressive']\n",
        "        third = image_features['imageOther']\n",
        "        test_input = np.array([first, second, third])\n",
        "\n",
        "        images = generatePrecise(encoder, decoder, test_input[0:3])\n",
        "        rs = recognizer.recognize(test_input[0:3], images)\n",
        "        ims = np.concatenate((test_input[0:3], images), axis=0)\n",
        "        assert not np.any(np.isnan(ims))\n",
        "        fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(6,4))\n",
        "        for i in range(ims.shape[0]):\n",
        "            c = i % 3\n",
        "            r = i // 3\n",
        "            axes[r, c].imshow(ims[i, :, :, 0], cmap='gray')\n",
        "            axes[r, c].set_yticklabels([])\n",
        "            axes[r, c].xaxis.set_visible(False)\n",
        "        axes[0,0].set_ylabel(\"Inputs\", size='large')\n",
        "        axes[1,0].set_ylabel(\"Generated\", size='large')\n",
        "        fig.tight_layout()\n",
        "        plt.savefig('novel_outputs.png')\n",
        "\n",
        "def display_imgs_ratings(test_input, epoch=-1):\n",
        "    images = generateImg(encoder, decoder, test_input[0:8])\n",
        "    rs = recognizer.recognize(test_input[0:8], images)\n",
        "    ims = np.concatenate((test_input[0:8], images), axis=0)\n",
        "    assert not np.any(np.isnan(ims))\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=8, figsize=(11,4))\n",
        "    ds = discriminator(ims)\n",
        "    for i in range(ims.shape[0]):\n",
        "        c = i % 8\n",
        "        r = i // 8\n",
        "        if r == 1:\n",
        "            axes[r, c].set_title(\"d {0:.6f}\\nr {1:.4f}\".format(ds[i,0], rs[c,0]))\n",
        "        else: \n",
        "            axes[r, c].set_title(\"d {0:.6f}\".format(ds[i,0]))\n",
        "        axes[r, c].imshow(ims[i, :, :, 0], cmap='gray')\n",
        "        axes[r, c].set_yticklabels([])\n",
        "        axes[r, c].xaxis.set_visible(False)\n",
        "    axes[0,0].set_ylabel(\"Inputs\", size='large')\n",
        "    axes[1,0].set_ylabel(\"Generated\", size='large')\n",
        "    fig.tight_layout()\n",
        "    if epoch >= 0:\n",
        "        plt.savefig('gens_ratings_at_epoch_{:04d}.png'.format(epoch))\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "def plot_ALL_loss(ls):\n",
        "    kl, rl, gl, dl, pl, il = zip(*ls)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.yaxis.tick_right()\n",
        "    plt.plot(kl, '-b', label='kL')\n",
        "    plt.plot(rl, '-g', label='rL')\n",
        "    plt.plot(gl, '-r', label='gL')\n",
        "    plt.plot(dl, '-m', label='dL')\n",
        "    plt.plot(pl, '-y', label='pL')\n",
        "    plt.plot(il, '-k', label='il')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXYOThHMQdx6",
        "colab_type": "text"
      },
      "source": [
        "# Training Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVDQ_wJVdezn",
        "colab_type": "code",
        "outputId": "6b40fcd0-82e9-411a-a1e5-4390e599c2de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "FRESH = True\n",
        "if not FRESH:\n",
        "    c = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "    print(\"Restoring checkpoint {0}\".format(c))\n",
        "    checkpoint.restore(c).assert_consumed()\n",
        "else:\n",
        "    print(\"Training a fresh model\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training a fresh model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "jqNw-Wqht8WG",
        "colab_type": "code",
        "outputId": "9a1c40ce-eea5-4403-9055-fbf4662e5661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "alpha = 0.0         # Alpha weights identity preservation loss.\n",
        "max_alpha = 15.0\n",
        "alpha_ramp_start = 10   # Ramps up\n",
        "alpha_ramp_end = 20\n",
        "\n",
        "beta = 0.0      # Beta weighs KL Divergence loss.\n",
        "max_beta = 1.0\n",
        "beta_ramp_start = -1   # Ramps up\n",
        "beta_ramp_end = 10\n",
        "\n",
        "gammaD = 0.05    # Gamma weighs reconstruction loss for the decoder\n",
        "max_gammaD = 0.05\n",
        "min_gammaD = 0.0\n",
        "gammaD_ramp_end = 20   # Ramps down\n",
        "\n",
        "gammaE = 0.05   # Gamma2 weighs reconstruction loss for the encoder (constant)\n",
        "\n",
        "ls = []\n",
        "bestLoss = 999999.9\n",
        "for epoch in range(0, epochs):\n",
        "\n",
        "    # Train\n",
        "    print(\"\\nTraining\", end=\"\")\n",
        "    start_time = time.time()\n",
        "    batchCounter = 0\n",
        "\n",
        "    alpha = min(max_alpha, max_alpha * (max(0,(epoch - alpha_ramp_start)) / alpha_ramp_end))\n",
        "    alpha = tf.convert_to_tensor(alpha, dtype=tf.float32)\n",
        "    beta = min(max_beta, max_beta * (max(0, (epoch - beta_ramp_start)) / beta_ramp_end))\n",
        "    beta = tf.convert_to_tensor(beta, dtype=tf.float32)\n",
        "    gammaD = min_gammaD + max_gammaD * max(0, 1 - (epoch / gammaD_ramp_end))\n",
        "    gammaD = tf.convert_to_tensor(gammaD, dtype=tf.float32)\n",
        "\n",
        "    for image_features in parsed_train:\n",
        "        neutral_raw = image_features['imageNeutral']\n",
        "        expressive_raw = image_features['imageExpressive']\n",
        "        other_raw = image_features['imageOther']\n",
        "\n",
        "        compute_apply_gradients(\n",
        "            encoder, decoder, discriminator, recognizer,\n",
        "            neutral_raw, expressive_raw, other_raw,\n",
        "            encOptimizer, decOptimizer, disOptimizer, idenOptimizer,\n",
        "            alpha, beta, gammaD, gammaE)\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "    \n",
        "    # Test\n",
        "    print(\"\\nTesting\", end=\"\")\n",
        "    batchCounter = 0\n",
        "    kloss = tf.keras.metrics.Mean()\n",
        "    rloss = tf.keras.metrics.Mean()\n",
        "    gloss = tf.keras.metrics.Mean()\n",
        "    dloss = tf.keras.metrics.Mean()\n",
        "    ploss = tf.keras.metrics.Mean()\n",
        "    iloss = tf.keras.metrics.Mean()\n",
        "    for image_features in parsed_test:\n",
        "        neutral_raw = image_features['imageNeutral']\n",
        "        expressive_raw = image_features['imageExpressive']\n",
        "        other_raw = image_features['imageOther']\n",
        "\n",
        "        kl, rl, gl, dl, pl, il = compute_ALL_loss(\n",
        "            encoder, decoder, discriminator, recognizer,\n",
        "            neutral_raw, expressive_raw, other_raw)\n",
        "        \n",
        "        kloss(kl)\n",
        "        rloss(rl)\n",
        "        gloss(gl)\n",
        "        dloss(dl)\n",
        "        ploss(pl)\n",
        "        iloss(il)\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "\n",
        "    kl = tf.math.multiply(kloss.result(), beta).numpy()\n",
        "    rl = tf.math.multiply(rloss.result(), gamma1).numpy()\n",
        "    gl = gloss.result().numpy()\n",
        "    dl = dloss.result().numpy()\n",
        "    pl = tf.math.multiply(ploss.result(), alpha).numpy()\n",
        "    il = iloss.result().numpy()\n",
        "    ls = ls + [(kl, rl, gl, dl, pl, il)]\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    # Output\n",
        "    display.clear_output(wait=False)\n",
        "    print('Epoch {0}, Total epoch time {1:.1f}\\nLosses: k {2:.5f} r {3:.5f} g {4:.5f} d {5:.5f} p {6:.5f} i {7:.5f}'.format(\n",
        "            epoch, end_time-start_time, kl, rl, gl, dl, pl, il))\n",
        "    print(\"Alpha(p): {0:.3f}, Beta(k): {1:.3f}, GammaD(r): {2:.3f}\".format(alpha, beta, gammaD))\n",
        "    display_imgs_ratings(random_images_for_generation)\n",
        "    save_images(epoch, random_vector_for_generation)\n",
        "    display_novel_images()\n",
        "    plot_ALL_loss(ls)\n",
        "\n",
        "    # Save the model from time to time or if you get a new record (after sufficient training)\n",
        "    if epoch > 25 and rl + gl + pl < bestLoss:\n",
        "        bestLoss = rl + gl + pl\n",
        "        best_checkpoint_prefix = os.path.join(checkpoint_dir, \"BEST_CKPT_\")\n",
        "        checkpoint.save(file_prefix=best_checkpoint_prefix)\n",
        "        print(\"*Saved new best*\")\n",
        "    elif (epoch + 1) % 10 == 0:\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix.format(epoch))\n",
        "\n",
        "    tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TrainingWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/linalg/linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not pass `graph_parents`.  They will  no longer be used.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MyW7bvwStaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"FINAL_CKPT_\" + time.strftime('%l:%M%b%d'))\n",
        "checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1l2PxZpcsQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anim_filename = BASE_DIR + 'TrainingGifs/vaegan' + time.strftime('%l:%M %b %d') + '.gif'\n",
        "print(anim_filename)\n",
        "with imageio.get_writer(anim_filename, mode='I') as writer:\n",
        "    filenames = glob.glob('image_at_epoch_*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    last = -1\n",
        "    for i,filename in enumerate(filenames):\n",
        "        frame = 2*(i**0.5)\n",
        "        if round(frame) > round(last):\n",
        "            last = frame\n",
        "        else:\n",
        "            continue\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhpVx7DzQYuB",
        "colab_type": "text"
      },
      "source": [
        "# Testing Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4i_YSqdQYQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointName = \"ckpt-4\" # \"FINAL_CKPT_12:05Mar22-18\"\n",
        "#checkpoint.restore(os.path.join(checkpoint_dir,checkpointName)).assert_nontrivial_match()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb_MvTfbRpW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_imgs_ratings(random_images_for_generation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irwxzovcnYum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_novel_images()\n",
        "print(encoder(test_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_8szW-z-LEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_images(-1, tf.math.scalar_mul(-0.8, tf.ones_like(random_vector_for_generation)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}