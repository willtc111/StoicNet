{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Trainer.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9IN3SD192go",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWEWOFA68xyU",
        "colab_type": "code",
        "outputId": "36a8fae2-2e9a-4d00-f0f5-741e71e57fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"tf version {0} executing eagerly is {1}\".format(tf.__version__, tf.executing_eagerly()))\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "print(\"tfp version {0}\".format(tfp.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version 2.2.0-rc2 executing eagerly is True\n",
            "tfp version 0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P59ok20-3v4",
        "colab_type": "code",
        "outputId": "d0d3d3c0-d32d-4c0d-9cdd-b89e0254ee7b",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = '/content/drive/My Drive/StoicNetData/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNWxIsIK9KvO",
        "colab_type": "code",
        "outputId": "19dc506f-b297-49e9-a420-85f03a52f650",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "USE_GPU = True\n",
        "if USE_GPU:\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    print(\"Device name: \\\"{0}\\\"\".format(device_name))\n",
        "    if device_name != '/device:GPU:0':\n",
        "        raise SystemError('GPU device not found')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            # Currently, memory growth needs to be the same across GPUs\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "        except RuntimeError as e:\n",
        "            # Memory growth must be set before GPUs have been initialized\n",
        "            print(e)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device name: \"/device:GPU:0\"\n",
            "Found GPU at: /device:GPU:0\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77kfnaVwt8Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import PIL\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('error', UserWarning)\n",
        "warnings.filterwarnings(\"error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFeV4R0mCQtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(98475651423)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts1EnJdX-V1f",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FbVWr08t8Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 112\n",
        "IMG_WIDTH = 112\n",
        "\n",
        "CK_keys_to_features = {\n",
        "    'image_neutral': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_expressive': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_other': tf.io.FixedLenFeature([], tf.string)\n",
        "}\n",
        "\n",
        "LFW_keys_to_features = {\n",
        "    'image': tf.io.FixedLenFeature([], tf.string)\n",
        "}\n",
        "\n",
        "def parserLFW(record):\n",
        "    parsed = tf.io.parse_single_example(record, LFW_keys_to_features)\n",
        "    \n",
        "    image = tf.io.decode_raw(parsed[\"image\"], tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.reshape(image, shape=[224,224,1])\n",
        "    image = tf.image.resize(image, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    image /= (255/2)\n",
        "    image -= 1\n",
        "    \n",
        "    return {\"image\":image}\n",
        "    \n",
        "def parserCK(record):\n",
        "    parsed = tf.io.parse_single_example(record, CK_keys_to_features)\n",
        "    \n",
        "    imageNeutral = tf.io.decode_raw(parsed[\"image_neutral\"], tf.uint8)\n",
        "    imageExpressive = tf.io.decode_raw(parsed[\"image_expressive\"], tf.uint8)\n",
        "    imageOther = tf.io.decode_raw(parsed[\"image_other\"], tf.uint8)\n",
        "    \n",
        "    imageNeutral = tf.cast(imageNeutral, tf.float32)\n",
        "    imageExpressive = tf.cast(imageExpressive, tf.float32)\n",
        "    imageOther = tf.cast(imageOther, tf.float32)\n",
        "    \n",
        "    imageNeutral = tf.reshape(imageNeutral, shape=[224,224,1])\n",
        "    imageExpressive = tf.reshape(imageExpressive, shape=[224,224,1])\n",
        "    imageOther = tf.reshape(imageOther, shape=[224,224,1])\n",
        "\n",
        "    imageNeutral = tf.image.resize(imageNeutral, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageExpressive = tf.image.resize(imageExpressive, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageOther = tf.image.resize(imageOther, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "\n",
        "    imageNeutral /= (255/2)\n",
        "    imageExpressive /= (255/2)\n",
        "    imageOther /= (255/2)\n",
        "    imageNeutral -= 1\n",
        "    imageExpressive -= 1\n",
        "    imageOther -= 1\n",
        "\n",
        "    return {\"imageNeutral\":imageNeutral, \"imageExpressive\":imageExpressive, \"imageOther\":imageOther}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtPS7faMt8V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 32\n",
        "latent_dim = 100\n",
        "\n",
        "DB_PATH = BASE_DIR\n",
        "\n",
        "\n",
        "raw_LFW_train = tf.data.TFRecordDataset(DB_PATH + \"trainLFW.tfrecords\")\n",
        "raw_LFW_test = tf.data.TFRecordDataset(DB_PATH + \"testLFW.tfrecords\")\n",
        "parsed_LFW_train = raw_LFW_train.map(parserLFW).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "parsed_LFW_test = raw_LFW_test.map(parserLFW).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "raw_CK_train = tf.data.TFRecordDataset(DB_PATH + \"train.tfrecords\")\n",
        "raw_CK_test = tf.data.TFRecordDataset(DB_PATH + \"test.tfrecords\")\n",
        "\n",
        "#raw_CK_val = raw_test.shard(2,0)\n",
        "#raw_CK_test = raw_test.shard(2,1)\n",
        "\n",
        "parsed_CK_train = raw_CK_train.map(parserCK).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "#parsed_CK_val = raw_val.map(parserCK).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "parsed_CK_test = raw_CK_test.map(parserCK).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "raw_novel = tf.data.TFRecordDataset(DB_PATH + \"novel.tfrecords\")\n",
        "parsed_novel = raw_novel.map(parserCK)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNgmQ6Wp-bA1",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8UhHQkBdxdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.random_normal_initializer(mean=0.0, stddev=0.02, seed=918273645)\n",
        "\n",
        "class Critic(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "        self.critique = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2), kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(512, kernel_initializer=init),\n",
        "            tf.keras.layers.LeakyReLU(),\n",
        "\n",
        "            tf.keras.layers.Dense(1, activation='linear', kernel_initializer=init),\n",
        "        ], name=\"critique\")\n",
        "    \n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        return self.critique(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8plw2BSFYrQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encode = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2), use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2), use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim, kernel_initializer=init), # no activation...\n",
        "        ], name=\"encode\")\n",
        "    \n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        mean, logvar = tf.split(self.encode(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.decode = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim)),\n",
        "\n",
        "            tf.keras.layers.Dense(units=7*7*256),\n",
        "            tf.keras.layers.Reshape(target_shape=(7, 7, 256)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=128, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=64, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=32, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=16, kernel_size=4, strides=(2, 2), padding=\"SAME\", use_bias=False, kernel_initializer=init),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", use_bias=False, kernel_initializer=init,\n",
        "                activation=\"tanh\"),\n",
        "        ], name=\"decode\")\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, x):\n",
        "        return self.decode(x)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def reparameterize(mean, logvar):\n",
        "    # Logvar used for numerical stability\n",
        "    epsilon = tf.random.normal(shape=mean.shape)\n",
        "    return epsilon * tf.exp(logvar * .5) + mean\n",
        "\n",
        "@tf.function\n",
        "def generateImg(enc, dec, x):\n",
        "    mean, logvar = enc(x)\n",
        "    return generateDist(dec, mean, logvar)\n",
        "\n",
        "@tf.function\n",
        "def generateDist(dec, mean, logvar):\n",
        "    z = reparameterize(mean, logvar)\n",
        "    return dec(z)\n",
        "\n",
        "@tf.function\n",
        "def generatePrecise(enc, dec, x):\n",
        "    z, _ = enc(x)\n",
        "    return dec(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnpWNN29-gTk",
        "colab_type": "text"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_UU3x3Vt8V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prior = tfp.distributions.MultivariateNormalDiag(tf.zeros(latent_dim), tf.ones(latent_dim))\n",
        "two = tf.convert_to_tensor(2.0, dtype=tf.float32)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def add_noise(x):\n",
        "    noise_intensity = 1.0\n",
        "    noise = tf.multiply(noise_intensity, tf.random.normal(shape=x.shape, mean=0.0, stddev=0.3))\n",
        "    return tf.clip_by_value(tf.add(x, noise), -1.0, 1.0)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_apply_gradients_critic_only(enc, dec, crt, x, crtOptimizer, Wkl, Wrl, Wgl):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        _, _, crtLoss = compute_loss(enc, dec, crt, x, Wkl, Wrl, Wgl)\n",
        "\n",
        "    gradients_of_crt = tape.gradient(crtLoss, crt.trainable_variables)\n",
        "    crtOptimizer.apply_gradients(zip(gradients_of_crt, crt.trainable_variables))\n",
        "\n",
        "@tf.function\n",
        "def compute_apply_gradients(enc, dec, crt, x, encOptimizer, decOptimizer, crtOptimizer, Wkl, Wrl, Wgl):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        encLoss, decLoss, crtLoss = compute_loss(enc, dec, crt, x, Wkl, Wrl, Wgl)\n",
        "\n",
        "    gradients_of_enc = tape.gradient(encLoss, enc.trainable_variables)\n",
        "    gradients_of_dec = tape.gradient(decLoss, dec.trainable_variables)\n",
        "    gradients_of_crt = tape.gradient(crtLoss, crt.trainable_variables)\n",
        "\n",
        "    encOptimizer.apply_gradients(zip(gradients_of_enc, enc.trainable_variables))\n",
        "    decOptimizer.apply_gradients(zip(gradients_of_dec, dec.trainable_variables))\n",
        "    crtOptimizer.apply_gradients(zip(gradients_of_crt, crt.trainable_variables))\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_loss(enc, dec, crt, x, Wkl, Wrl, Wgl):\n",
        "    #Compute loss values\n",
        "    klLoss, recLoss, genGanLoss, crtGanLoss = compute_ALL_loss(enc, dec, crt, x)\n",
        "\n",
        "    # (Wrl * rl) + (Wgl * gl)\n",
        "    outputLoss = tf.math.add(\n",
        "        tf.math.multiply(Wrl, recLoss),\n",
        "        tf.math.multiply(Wgl, genGanLoss)\n",
        "    )\n",
        "\n",
        "    encLoss = tf.math.add(  # (Wkl * kl) + outputLoss\n",
        "        tf.math.multiply(Wkl, klLoss),  \n",
        "        outputLoss\n",
        "    )\n",
        "    decLoss = outputLoss\n",
        "    crtLoss = crtGanLoss\n",
        "\n",
        "    return encLoss, decLoss, crtLoss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_ALL_loss(enc, dec, crt, x):\n",
        "    mean, logvar = enc(x)\n",
        "\n",
        "    # KL Divergence Loss\n",
        "    posterior = tfp.distributions.MultivariateNormalDiag(mean, tf.exp(logvar * .5))\n",
        "    divergenceLoss = tf.reduce_mean(tfp.distributions.kl_divergence(posterior, prior))\n",
        "\n",
        "    # Reconstruction Loss (MSE or RMSE)\n",
        "    generated_images = generateDist(dec, mean, logvar)\n",
        "    #tf.math.multiply(reconstructionMult, tf.math.sqrt(tf.reduce_mean(tf.math.square(tf.math.subtract(x, generated_images)))))\n",
        "    reconstructionLoss = tf.reduce_mean(tf.math.square(tf.math.subtract(x, generated_images)))\n",
        "    \n",
        "    real_scores = crt(x)    # May want to add noise?\n",
        "    fake_scores = crt(generated_images)\n",
        "    genGanLoss, crtGanLoss = compute_gan_loss(real_scores, fake_scores)#, sample_scores)\n",
        "\n",
        "    return divergenceLoss, reconstructionLoss, genGanLoss, crtGanLoss\n",
        "\n",
        "@tf.function\n",
        "def compute_gan_loss(real_output, fake_output):\n",
        "    dis_gan_loss = 0.5 * tf.add(\n",
        "        tf.reduce_mean((real_output - 1)**2),\n",
        "        tf.reduce_mean(fake_output**2)\n",
        "    )\n",
        "    gen_gan_loss = 0.5 * tf.reduce_mean((fake_output - 1)**2)\n",
        "    return gen_gan_loss, dis_gan_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYqTTseY-ji2",
        "colab_type": "text"
      },
      "source": [
        "# I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag2zm_9h5w01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_StoicNet(prefix, full=False):\n",
        "    if prefix is None:\n",
        "        path_to_save = BASE_DIR + \"saved_model\"\n",
        "    else:\n",
        "        path_to_save = BASE_DIR + \"saved_model/{}\".format(prefix)\n",
        "    !mkdir -p \"{path_to_save}\"\n",
        "    print('Saving model at \"{}\"'.format(path_to_save))\n",
        "    if full:\n",
        "        encoder.save(path_to_save + \"/encoder.h5\")\n",
        "        decoder.save(path_to_save + \"/decoder.h5\")\n",
        "        critic.save(path_to_save + \"/critic.h5\")\n",
        "    else:\n",
        "        encoder.save_weights(path_to_save + \"/encoder.h5\")\n",
        "        decoder.save_weights(path_to_save + \"/decoder.h5\")\n",
        "        critic.save_weights(path_to_save + \"/critic.h5\")\n",
        "\n",
        "\n",
        "def load_StoicNet(prefix):\n",
        "    if prefix is None:\n",
        "        path_to_save = BASE_DIR + \"saved_model\"\n",
        "    else:\n",
        "        path_to_save = BASE_DIR + \"saved_model/{}\".format(prefix)\n",
        "    \n",
        "    encoder.load_weights(path_to_save + \"/encoder.h5\")\n",
        "    decoder.load_weights(path_to_save + \"/decoder.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCD9--NTt8WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(epoch, test_input):\n",
        "    imgs = decoder(test_input)\n",
        "    assert not np.any(np.isnan(imgs))\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    for i in range(imgs.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    fig.tight_layout()\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def display_novel_images():\n",
        "    for image_features in parsed_novel:\n",
        "        first = image_features['imageNeutral']\n",
        "        second = image_features['imageExpressive']\n",
        "        third = image_features['imageOther']\n",
        "        test_input = np.array([first, second, third])\n",
        "\n",
        "        images = generatePrecise(encoder, decoder, test_input[0:3])\n",
        "        ims = np.concatenate((test_input[0:3], images), axis=0)\n",
        "        assert not np.any(np.isnan(ims))\n",
        "        fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(6,4))\n",
        "        for i in range(ims.shape[0]):\n",
        "            c = i % 3\n",
        "            r = i // 3\n",
        "            axes[r, c].imshow(ims[i, :, :, 0], cmap='gray')\n",
        "            axes[r, c].set_yticklabels([])\n",
        "            axes[r, c].xaxis.set_visible(False)\n",
        "        axes[0,0].set_ylabel(\"Inputs\", size='large')\n",
        "        axes[1,0].set_ylabel(\"Generated\", size='large')\n",
        "        fig.tight_layout()\n",
        "        #plt.savefig('novel_outputs.png')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def display_imgs_ratings(test_input, epoch=-1):\n",
        "    images = generateImg(encoder, decoder, test_input[0:8])\n",
        "    ims = np.concatenate((test_input[0:8], images), axis=0)\n",
        "    assert not np.any(np.isnan(ims))\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=8, figsize=(11,4))\n",
        "    ratings = critic(ims)\n",
        "    for i in range(ims.shape[0]):\n",
        "        c = i % 8\n",
        "        r = i // 8\n",
        "        axes[r, c].set_title(\"{0:.6f}\".format(ratings[i,0]))\n",
        "        axes[r, c].imshow(ims[i, :, :, 0], cmap='gray')\n",
        "        axes[r, c].set_yticklabels([])\n",
        "        axes[r, c].xaxis.set_visible(False)\n",
        "    axes[0,0].set_ylabel(\"Inputs\", size='large')\n",
        "    axes[1,0].set_ylabel(\"Generated\", size='large')\n",
        "    fig.tight_layout()\n",
        "    if epoch >= 0:\n",
        "        plt.savefig('gens_at_epoch_{:04d}.png'.format(epoch))\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_ALL_loss(ls):\n",
        "    kl, rl, gl, cl = zip(*ls)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.yaxis.tick_right()\n",
        "    plt.plot(kl, '-g', label='kL')\n",
        "    plt.plot(rl, '-b', label='rL')\n",
        "    plt.plot(gl, '-c', label='gL')\n",
        "    plt.plot(cl, '-r', label='cL')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_feature_changes(epoch=None):\n",
        "    startTime = time.time()\n",
        "    print(\"Generating Feature Visualization\", end='')\n",
        "    steps = 15\n",
        "    magnitude = 3.0\n",
        "\n",
        "    # Build the feature vectors\n",
        "    independent_feature_vectors = np.zeros(shape=[steps*2+1, latent_dim, latent_dim])\n",
        "    for step in range(-1*steps, steps+1):\n",
        "        step_index = step + steps\n",
        "        mag = magnitude * (step/steps)\n",
        "        for feature_index in range(0, latent_dim):\n",
        "            independent_feature_vectors[step_index, feature_index, feature_index] = mag\n",
        "    print(\"!\", end='')\n",
        "\n",
        "    # Make the images\n",
        "    for step_index in range(0, steps*2+1):\n",
        "        print(\".\", end='')\n",
        "        encoding = independent_feature_vectors[step_index]\n",
        "        imgs = decoder(encoding)\n",
        "        assert not np.any(np.isnan(imgs))\n",
        "        fig = plt.figure(figsize=(10,10))\n",
        "        for i in range(imgs.shape[0]):\n",
        "            plt.subplot(10, 10, i+1)\n",
        "            plt.imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "            plt.axis('off')\n",
        "        fig.tight_layout()\n",
        "        plt.savefig('frame_{0:03}.png'.format(step_index))\n",
        "        plt.close(fig)\n",
        "\n",
        "    # Make the animation\n",
        "    if epoch is None:\n",
        "        anim_filename = BASE_DIR + 'TrainingGifs/features_' + time.strftime('%l:%M_%b_%d') + '.gif'\n",
        "    else:\n",
        "        anim_filename = BASE_DIR + 'TrainingGifs/features_epoch_{}'.format(epoch) + time.strftime('%l:%M_%b_%d') + '.gif'\n",
        "    print(\"\\nSaving gif at: \" + anim_filename)\n",
        "    with imageio.get_writer(anim_filename, mode='I') as writer:\n",
        "        filenames = glob.glob('frame_*.png')\n",
        "        filenames = sorted(filenames)\n",
        "        filenames = filenames + filenames[::-1] # Go full circle\n",
        "        for i,filename in enumerate(filenames):\n",
        "            image = imageio.imread(filename)\n",
        "            writer.append_data(image)\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    print(\"Done in {} seconds\".format(time.time()-startTime))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXYOThHMQdx6",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QH0nPiz0yVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 150\n",
        "num_examples_to_generate = 16\n",
        "extra_critic_training_rounds = 0\n",
        "\n",
        "random_vector_for_generation = tf.random.normal(shape=[num_examples_to_generate, latent_dim])\n",
        "random_images_for_generation = [image_features['imageExpressive'] for image_features in parsed_CK_test.take(1)][0][0:num_examples_to_generate]\n",
        "\n",
        "encOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5)\n",
        "decOptimizer = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5)\n",
        "crtOptimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)\n",
        "\n",
        "encoder = Encoder(latent_dim)\n",
        "decoder = Decoder(latent_dim)\n",
        "critic = Critic()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVDQ_wJVdezn",
        "colab_type": "code",
        "outputId": "2f18826b-6d52-435c-a5db-4dbb5dc65458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "FRESH = True\n",
        "if not FRESH:\n",
        "    load_StoicNet(\"TEMP_SAVE\")\n",
        "    startEpoch = 90\n",
        "    print(\"Training loaded model from epoch {}\".format(startEpoch))\n",
        "else:\n",
        "    print(\"Training a fresh model\")\n",
        "    startEpoch = 0"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training a fresh model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "jqNw-Wqht8WG",
        "colab_type": "code",
        "outputId": "ad3b343c-f9f7-4f70-92a4-3121c4e179f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Wkl (aka beta) weighs KL Divergence loss, limiting encoding capacity \n",
        "Wkl = tf.convert_to_tensor(0.01, dtype=tf.float32)\n",
        "max_Wkl = 0.01\n",
        "Wkl_ramp_start = -1   # Ramps up\n",
        "Wkl_ramp_end = 10\n",
        "# Tried:\n",
        "# 0.001 (too low with Wrl=5, Wgl=1)\n",
        "# 0.01 () \n",
        "\n",
        "\n",
        "# Wrl weighs reconstruction loss\n",
        "Wrl = tf.convert_to_tensor(5.0, dtype=tf.float32)\n",
        "max_Wrl = 5.0\n",
        "Wrl_ramp_start = 1   # Ramps up\n",
        "Wrl_ramp_end = 15\n",
        "\n",
        "# Wgl weighs gan loss for generator\n",
        "Wgl = tf.convert_to_tensor(1.0, dtype=tf.float32)\n",
        "max_Wrl = 1.0\n",
        "Wrl_ramp_start = 1   # Ramps up\n",
        "Wrl_ramp_end = 15\n",
        "\n",
        "ls = []\n",
        "bestLoss = 999999.9\n",
        "start_time = time.time()\n",
        "for epoch in range(startEpoch, epochs):\n",
        "    # Train\n",
        "    Wkl = min(max_Wkl, max_Wkl * (max(0, (epoch - Wkl_ramp_start)) / (Wkl_ramp_end - Wkl_ramp_start)))\n",
        "    Wkl = tf.convert_to_tensor(Wkl, dtype=tf.float32)\n",
        "\n",
        "    batchCounter = 0\n",
        "    for training_round in range(0, extra_critic_training_rounds):\n",
        "        print(\"\\nTraining Critic Round {}\".format(training_round), end=\"\")\n",
        "\n",
        "        for image_features in parsed_LFW_train:\n",
        "            image_raw = image_features['image']\n",
        "\n",
        "            compute_apply_gradients_critic_only(\n",
        "                encoder, decoder, critic,\n",
        "                image_raw, crtOptimizer,\n",
        "                Wkl, Wrl, Wgl)\n",
        "\n",
        "            batchCounter += 1\n",
        "            if batchCounter % 10 == 0:\n",
        "                print(\".\", end=\"\")\n",
        "    \n",
        "    print(\"\\nTraining All\", end=\"\")\n",
        "    batchCounter = 0\n",
        "    for image_features in parsed_LFW_train:\n",
        "        image_raw = image_features['image']\n",
        "\n",
        "        compute_apply_gradients(\n",
        "            encoder, decoder, critic,\n",
        "            image_raw,\n",
        "            encOptimizer, decOptimizer, crtOptimizer,\n",
        "            Wkl, Wrl, Wgl)\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "    \n",
        "    # Test\n",
        "    print(\"\\nTesting All\", end=\"\")\n",
        "    batchCounter = 0\n",
        "    kloss = tf.keras.metrics.Mean()\n",
        "    rloss = tf.keras.metrics.Mean()\n",
        "    gloss = tf.keras.metrics.Mean()\n",
        "    closs = tf.keras.metrics.Mean()\n",
        "    for image_features in parsed_LFW_test:\n",
        "        image_raw = image_features['image']\n",
        "\n",
        "        kl, rl, gl, cl = compute_ALL_loss(\n",
        "            encoder, decoder, critic,\n",
        "            image_raw)\n",
        "        \n",
        "        kloss(kl)\n",
        "        rloss(rl)\n",
        "        gloss(gl)\n",
        "        closs(cl)\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "\n",
        "    kl_base = kloss.result().numpy()\n",
        "    kl = tf.math.multiply(kloss.result(), Wkl).numpy()\n",
        "    rl = tf.math.multiply(rloss.result(), Wrl).numpy()\n",
        "    gl = tf.math.multiply(gloss.result(), Wgl).numpy()\n",
        "    cl = closs.result().numpy()\n",
        "    ls = ls + [(kl, rl, gl, cl)]\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    # Output\n",
        "    display.clear_output(wait=False)\n",
        "    print('Epoch {0}, Total epoch time {1:.1f}'.format(epoch, end_time-start_time))\n",
        "    print('Losses: k {0:.5f}({1:.5f}x{2:.5f})  r {3:.5f}  g {4:.5f}  c {5:.5f}'.format(\n",
        "            kl, Wkl, kl_base, rl, gl, cl))\n",
        "    plot_ALL_loss(ls)\n",
        "    display_imgs_ratings(random_images_for_generation)\n",
        "    #save_images(epoch, random_vector_for_generation)\n",
        "    #display_novel_images()\n",
        "\n",
        "\n",
        "    # Save the model from time to time or if you get a new record (after sufficient training)\n",
        "    if epoch > 20 and kl + rl + gl < bestLoss:\n",
        "        bestLoss = kl + rl + gl\n",
        "        save_StoicNet(\"TEMP_BEST_MODEL\")\n",
        "        print(\"*Saved new best*\")\n",
        "    elif (epoch + 1) % 25 == 0:\n",
        "        display_feature_changes(epoch+1)\n",
        "        save_StoicNet(\"TEMP_SAVE\")\n",
        "    elif (epoch + 1) % 5 == 0:\n",
        "        save_StoicNet(\"TEMP_SAVE\")\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training AllWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not pass `graph_parents`.  They will  no longer be used.\n",
            "........................................................."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhpVx7DzQYuB",
        "colab_type": "text"
      },
      "source": [
        "# Save & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MyW7bvwStaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveName = \"FINAL_SAVE_\"+time.strftime('%l_%M_%b%d')\n",
        "save_StoicNet(saveName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxmHNJVTk1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_feature_changes()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1l2PxZpcsQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# anim_filename = BASE_DIR + 'TrainingGifs/vaegan' + time.strftime('%l:%M %b %d') + '.gif'\n",
        "# print(anim_filename)\n",
        "# with imageio.get_writer(anim_filename, mode='I') as writer:\n",
        "#     filenames = glob.glob('image_at_epoch_*.png')\n",
        "#     filenames = sorted(filenames)\n",
        "#     last = -1\n",
        "#     for i,filename in enumerate(filenames):\n",
        "#         frame = 2*(i**0.5)\n",
        "#         if round(frame) > round(last):\n",
        "#             last = frame\n",
        "#         else:\n",
        "#             continue\n",
        "#         image = imageio.imread(filename)\n",
        "#         writer.append_data(image)\n",
        "#     image = imageio.imread(filename)\n",
        "#     writer.append_data(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4i_YSqdQYQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(latent_dim)\n",
        "decoder = Decoder(latent_dim)\n",
        "load_StoicNet(saveName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb_MvTfbRpW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_imgs_ratings(random_images_for_generation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irwxzovcnYum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_novel_images()\n",
        "print(encoder(test_input))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}