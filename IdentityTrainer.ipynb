{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IdentityTrainer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6yFPkl8gQeeSM+g/rqqaa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0IeyRJ1fiI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0ab4b8aa-4a50-45b6-ecf2-edb6e6f876cd"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"tf version {0} executing eagerly is {1}\".format(tf.__version__, tf.executing_eagerly()))\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "print(\"tfp version {0}\".format(tfp.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "tf version 2.1.0 executing eagerly is True\n",
            "tfp version 0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AnMN7U1f-x6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "bda78661-7912-4e0a-d020-e2b440c81e5b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = '/content/drive/My Drive/StoicNetData/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEj681rWf_Ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b28ee834-abb5-4b5d-eb53-0fdff344d953"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "print(\"Device name: \\\"{0}\\\"\".format(device_name))\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device name: \"/device:GPU:0\"\n",
            "Found GPU at: /device:GPU:0\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YlAHgeMf_Q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import PIL\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('error', UserWarning)\n",
        "warnings.filterwarnings(\"error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mC_WhmbgGN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(98475651423)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN8fhiDhgIfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_HEIGHT = 112\n",
        "IMG_WIDTH = 112\n",
        "\n",
        "keys_to_features = {\n",
        "    'image_neutral': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_expressive': tf.io.FixedLenFeature([], tf.string),\n",
        "    'image_other': tf.io.FixedLenFeature([], tf.string)\n",
        "}\n",
        "\n",
        "def parser(record):\n",
        "    parsed = tf.io.parse_single_example(record, keys_to_features)\n",
        "    \n",
        "    imageNeutral = tf.io.decode_raw(parsed[\"image_neutral\"], tf.uint8)\n",
        "    imageExpressive = tf.io.decode_raw(parsed[\"image_expressive\"], tf.uint8)\n",
        "    imageOther = tf.io.decode_raw(parsed[\"image_other\"], tf.uint8)\n",
        "    \n",
        "    imageNeutral = tf.cast(imageNeutral, tf.float32)\n",
        "    imageExpressive = tf.cast(imageExpressive, tf.float32)\n",
        "    imageOther = tf.cast(imageOther, tf.float32)\n",
        "    \n",
        "    imageNeutral = tf.reshape(imageNeutral, shape=[224,224,1])\n",
        "    imageExpressive = tf.reshape(imageExpressive, shape=[224,224,1])\n",
        "    imageOther = tf.reshape(imageOther, shape=[224,224,1])\n",
        "\n",
        "    imageNeutral = tf.image.resize(imageNeutral, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageExpressive = tf.image.resize(imageExpressive, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "    imageOther = tf.image.resize(imageOther, size=[IMG_HEIGHT,IMG_WIDTH])\n",
        "\n",
        "    imageNeutral /= (255/2)\n",
        "    imageExpressive /= (255/2)\n",
        "    imageOther /= (255/2)\n",
        "    imageNeutral -= 1\n",
        "    imageExpressive -= 1\n",
        "    imageOther -= 1\n",
        "\n",
        "    return {\"imageNeutral\":imageNeutral, \"imageExpressive\":imageExpressive, \"imageOther\":imageOther}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWAUnWlngLGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "69525537-9f09-46f9-8150-732d66716129"
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "DB_PATH = BASE_DIR\n",
        "raw_train = tf.data.TFRecordDataset(DB_PATH + \"train.tfrecords\")\n",
        "raw_test = tf.data.TFRecordDataset(DB_PATH + \"test.tfrecords\")\n",
        "\n",
        "parsed_train = raw_train.map(parser).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "parsed_test = raw_test.map(parser).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "print(parsed_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: {imageNeutral: (None, 112, 112, 1), imageExpressive: (None, 112, 112, 1), imageOther: (None, 112, 112, 1)}, types: {imageNeutral: tf.float32, imageExpressive: tf.float32, imageOther: tf.float32}>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J666ygWZlKfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TripletLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, alpha):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        anc = y_pred[0]; pos = y_pred[1]; neg = y_pred[2]\n",
        "        # distance between the anchor and the positive\n",
        "        #pos_dist = tf.reduce_sum(tf.square(tf.subtract(anc, pos)), axis=-1)\n",
        "        pos_dist = tf.reduce_sum(tf.subtract(anc, pos), axis=-1)    \n",
        "        # distance between the anchor and the negative\n",
        "        #neg_dist = tf.reduce_sum(tf.square(tf.subtract(anc, neg)), axis=-1)\n",
        "        neg_dist = tf.reduce_sum(tf.subtract(anc, neg), axis=-1)\n",
        "        \n",
        "        return tf.math.maximum(tf.add(tf.subtract(pos_dist, neg_dist), self.alpha), 0.0)\n",
        "\n",
        "\n",
        "alpha = tf.convert_to_tensor(0.2, dtype=tf.float32)\n",
        "triplet_loss = TripletLoss(alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEwBNyIAgMvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recognizer(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Recognizer, self).__init__()\n",
        "        self.encoder = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        " \n",
        "            tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=(2,2)),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.ReLU(),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(latent_dim)\n",
        "        ], name=\"encoder\")\n",
        "\n",
        "        self.comparer = tf.keras.models.Sequential(layers=[\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim)),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ], name=\"comparer\")\n",
        "\n",
        "    \n",
        "    @tf.function\n",
        "    def recognize(self, a, b):\n",
        "        a_encoding = recognizer(a)\n",
        "        b_encoding = recognizer(b)\n",
        "\n",
        "        diffs = tf.abs(a_encoding - b_encoding)\n",
        "\n",
        "        prediction = comparer(diffs)\n",
        "        return prediction\n",
        "\n",
        "\n",
        "\n",
        "latent_dim = 100\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00006, beta_1=0.5)\n",
        "recognizer = Recognizer(latent_dim)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mck7QyGsxqy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = BASE_DIR + 'training_checkpoints/recog_training_1/cp.ckpt'\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,recognizer=recognizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJY_c2t_GsTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(ls):\n",
        "    fig = plt.figure()\n",
        "    plt.plot(ls, 'r')\n",
        "    plt.title(\"Loss\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UrPOlE6EkfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(rec, x_neutral, x_express, x_other):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "    pos_preds = rec.recognize(x_express, x_neutral)\n",
        "    neg_preds = rec.recognize(x_express, x_other)\n",
        "    \n",
        "    pos_labels = tf.ones_like(pos_preds)\n",
        "    pos_loss = cross_entropy(pos_labels, pos_preds)\n",
        "\n",
        "    neg_labels = tf.zeros_like(neg_preds)\n",
        "    neg_loss = cross_entropy(neg_labels, neg_preds)\n",
        "\n",
        "    return pos_loss + neg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X9nONSPD1ce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "ed267c57-549f-4894-91b0-9ea43b4e1988"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "ls = []\n",
        "loss = -1\n",
        "start_time = end_time = 0\n",
        "for epoch in range(1, epochs+1):\n",
        "    print('Epoch {0}, Test set loss {1}, time elapsed for current epoch {2:.1f}'.format(\n",
        "        epoch, loss, end_time - start_time))\n",
        "    # Test\n",
        "    loss = tf.keras.metrics.Mean()\n",
        "    for image_features in parsed_test:\n",
        "        l = compute_loss(recognizer, neutral_raw, expressive_raw, other_raw)\n",
        "        loss(l)\n",
        "    l = loss.result()\n",
        "    ls = ls + [l]\n",
        "\n",
        "    plot_loss(ls)\n",
        "\n",
        "\n",
        "    # Train\n",
        "    start_time = time.time()\n",
        "    batchCounter = 0\n",
        "    for image_features in parsed_train:\n",
        "        neutral_raw = image_features['imageNeutral']\n",
        "        assert not np.any(np.isnan(neutral_raw))\n",
        "        expressive_raw = image_features['imageExpressive']\n",
        "        assert not np.any(np.isnan(expressive_raw))\n",
        "        other_raw = image_features['imageOther']\n",
        "        assert not np.any(np.isnan(other_raw))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = compute_loss(recognizer, neutral_raw, expressive_raw, other_raw)\n",
        "        \n",
        "        gradients = tape.gradient(loss, recognizer.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, recognizer.trainable_variables))\n",
        "\n",
        "        batchCounter += 1\n",
        "        if batchCounter % 10 == 0:\n",
        "            print(\".\", end=\"\")\n",
        "    end_time = time.time()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Test set loss -1, time elapsed for current epoch 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-e2c6c74bc642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_features\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecognizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneutral_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpressive_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'neutral_raw' is not defined"
          ]
        }
      ]
    }
  ]
}