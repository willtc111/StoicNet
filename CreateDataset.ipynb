{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "import csv\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(addr):\n",
    "    img = cv2.imread(addr)\n",
    "    if not img is None:\n",
    "        # Convert it to grayscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataRecord(outputAddr, inputAddrs, doAugs):\n",
    "    writer = tf.io.TFRecordWriter(outputAddr)\n",
    "    \n",
    "    for i in range(len(inputAddrs)):\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(\"{0} of {1} images completed\".format(i, len(inputAddrs)))\n",
    "        \n",
    "        imgNeutral = loadImage(inputAddrs[i][0])\n",
    "        imgExpressive = loadImage(inputAddrs[i][1])\n",
    "        \n",
    "        if imgNeutral is None or imgExpressive is None:\n",
    "            continue\n",
    "        \n",
    "        # This is an augmented sample, alter the expressive face\n",
    "        if doAugs[i] == 1:\n",
    "            imgExpressive = augment(imgExpressive)\n",
    "        \n",
    "        # Resize\n",
    "        imgNeutral = cv2.resize(imgNeutral, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        imgExpressive = cv2.resize(imgExpressive, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Serialize\n",
    "        feature = {\n",
    "            'image_neutral': _bytes_feature(imgNeutral.tostring()),\n",
    "            'image_expressive': _bytes_feature(imgExpressive.tostring())\n",
    "        }\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateImage(image, angle):\n",
    "    center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x: tf.Tensor) -> tf.Tensor:\n",
    "    whichAug = tf.random.uniform(shape=[1], minval=0, maxval=2, dtype=tf.dtypes.int32)\n",
    "    if whichAug == 0:\n",
    "        # Rotate\n",
    "        rotation = tf.random.uniform(shape=[1], minval=-5, maxval=5, dtype=tf.dtypes.float32)\n",
    "        x = rotateImage(x, rotation * math.pi / 180)\n",
    "    elif whichAug == 1:\n",
    "        # Translate (no more than 15 up or down)\n",
    "        vertTrans = tf.random.uniform(shape=[1], minval=-9, maxval=10, dtype=tf.dtypes.int32)\n",
    "        x = x[9+int(vertTrans):246+int(vertTrans), 9:246]\n",
    "        \n",
    "    sys.stdout.flush()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbBasePath = 'C:\\\\Users\\\\Will\\\\Documents\\\\StoicNetData\\\\'\n",
    "\n",
    "with open(dbBasePath + r'pairs.txt', newline = '') as pairData:\n",
    "    pairReader = csv.reader(pairData, delimiter='\\t')\n",
    "    pairs = [[dbBasePath + p for p in pair] for pair in pairReader]\n",
    "\n",
    "# Double the pairs, and label the second half to be altered for augmentation\n",
    "augs = ([0] * len(pairs)) + ([1] * len(pairs))\n",
    "pairs = pairs + list.copy(pairs)\n",
    "\n",
    "# Shuffle the pairs (and keep the augmentation labels with them)\n",
    "c = list(zip(pairs, augs))\n",
    "shuffle(c)\n",
    "pairs, augs = zip(*c)\n",
    "\n",
    "# 60/20/20 train/val/test split\n",
    "trainPairs = pairs[0:int(0.6*len(pairs))]\n",
    "trainAugs = augs[0:int(0.6*len(augs))]\n",
    "valPairs = pairs[int(0.6*len(pairs)):int(0.8*len(pairs))]\n",
    "valAugs = augs[int(0.6*len(pairs)):int(0.8*len(augs))]\n",
    "testPairs = pairs[int(0.8*len(pairs)):]\n",
    "testAugs = augs[int(0.8*len(augs)):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 12849 images completed\n",
      "1000 of 12849 images completed\n",
      "2000 of 12849 images completed\n",
      "3000 of 12849 images completed\n",
      "4000 of 12849 images completed\n",
      "5000 of 12849 images completed\n",
      "6000 of 12849 images completed\n",
      "7000 of 12849 images completed\n",
      "8000 of 12849 images completed\n",
      "9000 of 12849 images completed\n",
      "10000 of 12849 images completed\n",
      "11000 of 12849 images completed\n",
      "12000 of 12849 images completed\n",
      "0 of 4283 images completed\n",
      "1000 of 4283 images completed\n",
      "2000 of 4283 images completed\n",
      "3000 of 4283 images completed\n",
      "4000 of 4283 images completed\n",
      "0 of 4284 images completed\n",
      "1000 of 4284 images completed\n",
      "2000 of 4284 images completed\n",
      "3000 of 4284 images completed\n",
      "4000 of 4284 images completed\n"
     ]
    }
   ],
   "source": [
    "createDataRecord(dbBasePath + 'train.tfrecords', trainPairs, trainAugs)\n",
    "createDataRecord(dbBasePath + 'val.tfrecords', valPairs, valAugs)\n",
    "createDataRecord(dbBasePath + 'test.tfrecords', testPairs, testAugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
